{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb0e60d",
   "metadata": {},
   "source": [
    "Baseline_TF\n",
    "https://www.kaggle.com/code/ivaneleskin/baseline-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d547408f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:32:00.244419Z",
     "start_time": "2023-02-27T20:31:58.602851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:31:58.882809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 12:31:59.029560: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-27 12:31:59.504526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-02-27 12:31:59.504585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-02-27 12:31:59.504589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import missingno as msno\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6754b0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:32:00.334715Z",
     "start_time": "2023-02-27T20:32:00.246195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 94477 rows, 4 cols\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  \n",
       "0   blow  \n",
       "1   wait  \n",
       "2  cloud  \n",
       "3   bird  \n",
       "4   owie  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path('..')\n",
    "DF_TRAIN = DATA_ROOT / 'train.csv'\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "train.info()\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986d1ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:53:45.403059Z",
     "start_time": "2023-02-27T18:53:45.006670Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c117e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:32:00.340374Z",
     "start_time": "2023-02-27T20:32:00.336159Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = \"../\"\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bc1555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:32:00.430981Z",
     "start_time": "2023-02-27T20:32:00.341842Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53117b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:36:43.678400Z",
     "start_time": "2023-02-27T20:32:00.432404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 94477/94477 [04:42<00:00, 334.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    94477.000000\n",
      "mean        37.935021\n",
      "std         44.177069\n",
      "min          2.000000\n",
      "25%         12.000000\n",
      "50%         22.000000\n",
      "75%         44.000000\n",
      "max        537.000000\n",
      "Name: num_frames, dtype: float64\n",
      "(94477, 543, 3) (94477,)\n"
     ]
    }
   ],
   "source": [
    "if CFG.is_training:\n",
    "    print('True')\n",
    "    if CFG.use_aggregation_dataset == True:\n",
    "        print('True')\n",
    "        xs, ys = [], []\n",
    "        num_frames = np.zeros(len(train))\n",
    "        for i in tqdm(range(len(train))):\n",
    "            path = f\"{CFG.data_path}{train.iloc[i].path}\"\n",
    "            data = load_relevant_data_subset_with_imputation(path)\n",
    "            ## Mean Aggregation\n",
    "            xs.append(np.mean(data, axis=0))\n",
    "            ys.append(train.iloc[i].label)\n",
    "            num_frames[i] = data.shape[0]\n",
    "            if CFG.quick_experiment and i == 4999:\n",
    "                break\n",
    "        ## Save number of frames of each training sample for data analysis\n",
    "        train[\"num_frames\"] = num_frames\n",
    "        X, y = np.array(xs), np.array(ys)\n",
    "        print(train[\"num_frames\"].describe())\n",
    "        train.to_csv(\"train.csv\", index=False)\n",
    "    else:\n",
    "        X = np.load(\"../X.npy\")\n",
    "        y = np.load(\"../y.npy\")\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29000a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:36:43.683721Z",
     "start_time": "2023-02-27T20:36:43.679429Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.Input((543, 3), dtype=tf.float32)\n",
    "    h1 = tf.keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "    h2 = tf.keras.layers.Dense(64, activation=\"relu\")(h1)\n",
    "    h3 = tf.keras.layers.Dense(64, activation=\"relu\")(h2)\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate()([inputs, h3])\n",
    "    vector = tf.keras.layers.Dense(64, activation=\"relu\")(concat)\n",
    "    vector = tf.keras.layers.Dense(32, activation=\"relu\")(vector)\n",
    "    vector = tf.keras.layers.Dense(32, activation=\"relu\")(vector)\n",
    "    vector = tf.keras.layers.Flatten()(vector)\n",
    "    output = tf.keras.layers.Dense(250, activation=\"softmax\")(vector)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top-5-accuracy\"),\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab087c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:08:38.022381Z",
     "start_time": "2023-02-27T21:02:33.730106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75581, 543, 3) (75581,) (18896, 543, 3) (18896,)\n",
      "Epoch 1/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 5.3238 - accuracy: 0.0198 - top-5-accuracy: 0.0754 - sparse_top_k_categorical_accuracy: 0.1264 - val_loss: 5.0131 - val_accuracy: 0.0464 - val_top-5-accuracy: 0.1587 - val_sparse_top_k_categorical_accuracy: 0.2412\n",
      "Epoch 2/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 4.7703 - accuracy: 0.0736 - top-5-accuracy: 0.2162 - sparse_top_k_categorical_accuracy: 0.3195 - val_loss: 4.6079 - val_accuracy: 0.0946 - val_top-5-accuracy: 0.2659 - val_sparse_top_k_categorical_accuracy: 0.3826\n",
      "Epoch 3/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 4.3250 - accuracy: 0.1294 - top-5-accuracy: 0.3317 - sparse_top_k_categorical_accuracy: 0.4524 - val_loss: 4.2983 - val_accuracy: 0.1452 - val_top-5-accuracy: 0.3584 - val_sparse_top_k_categorical_accuracy: 0.4786\n",
      "Epoch 4/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 4.0393 - accuracy: 0.1714 - top-5-accuracy: 0.4019 - sparse_top_k_categorical_accuracy: 0.5237 - val_loss: 4.0774 - val_accuracy: 0.1684 - val_top-5-accuracy: 0.3955 - val_sparse_top_k_categorical_accuracy: 0.5155\n",
      "Epoch 5/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.8484 - accuracy: 0.2014 - top-5-accuracy: 0.4473 - sparse_top_k_categorical_accuracy: 0.5685 - val_loss: 4.0005 - val_accuracy: 0.1934 - val_top-5-accuracy: 0.4313 - val_sparse_top_k_categorical_accuracy: 0.5517\n",
      "Epoch 6/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 3.7096 - accuracy: 0.2256 - top-5-accuracy: 0.4781 - sparse_top_k_categorical_accuracy: 0.5974 - val_loss: 3.8697 - val_accuracy: 0.1952 - val_top-5-accuracy: 0.4346 - val_sparse_top_k_categorical_accuracy: 0.5607\n",
      "Epoch 7/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.5925 - accuracy: 0.2438 - top-5-accuracy: 0.5039 - sparse_top_k_categorical_accuracy: 0.6214 - val_loss: 3.7980 - val_accuracy: 0.2236 - val_top-5-accuracy: 0.4701 - val_sparse_top_k_categorical_accuracy: 0.5913\n",
      "Epoch 8/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 3.4950 - accuracy: 0.2609 - top-5-accuracy: 0.5262 - sparse_top_k_categorical_accuracy: 0.6433 - val_loss: 3.8732 - val_accuracy: 0.1981 - val_top-5-accuracy: 0.4382 - val_sparse_top_k_categorical_accuracy: 0.5640\n",
      "Epoch 9/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 3.4095 - accuracy: 0.2737 - top-5-accuracy: 0.5430 - sparse_top_k_categorical_accuracy: 0.6591 - val_loss: 3.7739 - val_accuracy: 0.2243 - val_top-5-accuracy: 0.4775 - val_sparse_top_k_categorical_accuracy: 0.5992\n",
      "Epoch 10/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.3363 - accuracy: 0.2865 - top-5-accuracy: 0.5588 - sparse_top_k_categorical_accuracy: 0.6724 - val_loss: 3.7226 - val_accuracy: 0.2385 - val_top-5-accuracy: 0.4975 - val_sparse_top_k_categorical_accuracy: 0.6136\n",
      "Epoch 11/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.2755 - accuracy: 0.2995 - top-5-accuracy: 0.5714 - sparse_top_k_categorical_accuracy: 0.6817 - val_loss: 3.6980 - val_accuracy: 0.2278 - val_top-5-accuracy: 0.4817 - val_sparse_top_k_categorical_accuracy: 0.6034\n",
      "Epoch 12/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.2188 - accuracy: 0.3072 - top-5-accuracy: 0.5796 - sparse_top_k_categorical_accuracy: 0.6917 - val_loss: 3.7410 - val_accuracy: 0.2495 - val_top-5-accuracy: 0.5094 - val_sparse_top_k_categorical_accuracy: 0.6255\n",
      "Epoch 13/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.1709 - accuracy: 0.3171 - top-5-accuracy: 0.5935 - sparse_top_k_categorical_accuracy: 0.7009 - val_loss: 3.6509 - val_accuracy: 0.2613 - val_top-5-accuracy: 0.5236 - val_sparse_top_k_categorical_accuracy: 0.6388\n",
      "Epoch 14/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.1223 - accuracy: 0.3264 - top-5-accuracy: 0.5999 - sparse_top_k_categorical_accuracy: 0.7087 - val_loss: 3.6102 - val_accuracy: 0.2580 - val_top-5-accuracy: 0.5160 - val_sparse_top_k_categorical_accuracy: 0.6324\n",
      "Epoch 15/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.0789 - accuracy: 0.3340 - top-5-accuracy: 0.6090 - sparse_top_k_categorical_accuracy: 0.7172 - val_loss: 3.6116 - val_accuracy: 0.2647 - val_top-5-accuracy: 0.5328 - val_sparse_top_k_categorical_accuracy: 0.6465\n",
      "Epoch 16/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 3.0392 - accuracy: 0.3395 - top-5-accuracy: 0.6172 - sparse_top_k_categorical_accuracy: 0.7248 - val_loss: 3.5498 - val_accuracy: 0.2703 - val_top-5-accuracy: 0.5373 - val_sparse_top_k_categorical_accuracy: 0.6543\n",
      "Epoch 17/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 3.0020 - accuracy: 0.3488 - top-5-accuracy: 0.6236 - sparse_top_k_categorical_accuracy: 0.7289 - val_loss: 3.4903 - val_accuracy: 0.2709 - val_top-5-accuracy: 0.5449 - val_sparse_top_k_categorical_accuracy: 0.6605\n",
      "Epoch 18/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.9667 - accuracy: 0.3531 - top-5-accuracy: 0.6318 - sparse_top_k_categorical_accuracy: 0.7358 - val_loss: 3.6138 - val_accuracy: 0.2697 - val_top-5-accuracy: 0.5328 - val_sparse_top_k_categorical_accuracy: 0.6484\n",
      "Epoch 19/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.9373 - accuracy: 0.3584 - top-5-accuracy: 0.6366 - sparse_top_k_categorical_accuracy: 0.7405 - val_loss: 3.5375 - val_accuracy: 0.2655 - val_top-5-accuracy: 0.5338 - val_sparse_top_k_categorical_accuracy: 0.6514\n",
      "Epoch 20/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.9045 - accuracy: 0.3668 - top-5-accuracy: 0.6423 - sparse_top_k_categorical_accuracy: 0.7444 - val_loss: 3.6165 - val_accuracy: 0.2725 - val_top-5-accuracy: 0.5425 - val_sparse_top_k_categorical_accuracy: 0.6559\n",
      "Epoch 21/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.8725 - accuracy: 0.3709 - top-5-accuracy: 0.6495 - sparse_top_k_categorical_accuracy: 0.7513 - val_loss: 3.5710 - val_accuracy: 0.2824 - val_top-5-accuracy: 0.5540 - val_sparse_top_k_categorical_accuracy: 0.6673\n",
      "Epoch 22/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.8396 - accuracy: 0.3769 - top-5-accuracy: 0.6578 - sparse_top_k_categorical_accuracy: 0.7557 - val_loss: 3.5738 - val_accuracy: 0.2740 - val_top-5-accuracy: 0.5394 - val_sparse_top_k_categorical_accuracy: 0.6566\n",
      "Epoch 23/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.8156 - accuracy: 0.3821 - top-5-accuracy: 0.6603 - sparse_top_k_categorical_accuracy: 0.7598 - val_loss: 3.6355 - val_accuracy: 0.2830 - val_top-5-accuracy: 0.5493 - val_sparse_top_k_categorical_accuracy: 0.6634\n",
      "Epoch 24/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.7844 - accuracy: 0.3866 - top-5-accuracy: 0.6669 - sparse_top_k_categorical_accuracy: 0.7646 - val_loss: 3.4843 - val_accuracy: 0.2767 - val_top-5-accuracy: 0.5449 - val_sparse_top_k_categorical_accuracy: 0.6606\n",
      "Epoch 25/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.7596 - accuracy: 0.3933 - top-5-accuracy: 0.6704 - sparse_top_k_categorical_accuracy: 0.7671 - val_loss: 3.5787 - val_accuracy: 0.2893 - val_top-5-accuracy: 0.5579 - val_sparse_top_k_categorical_accuracy: 0.6680\n",
      "Epoch 26/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.7349 - accuracy: 0.3980 - top-5-accuracy: 0.6744 - sparse_top_k_categorical_accuracy: 0.7711 - val_loss: 3.4909 - val_accuracy: 0.2854 - val_top-5-accuracy: 0.5531 - val_sparse_top_k_categorical_accuracy: 0.6676\n",
      "Epoch 27/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.7090 - accuracy: 0.4022 - top-5-accuracy: 0.6794 - sparse_top_k_categorical_accuracy: 0.7751 - val_loss: 3.4867 - val_accuracy: 0.2834 - val_top-5-accuracy: 0.5593 - val_sparse_top_k_categorical_accuracy: 0.6744\n",
      "Epoch 28/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.6806 - accuracy: 0.4073 - top-5-accuracy: 0.6846 - sparse_top_k_categorical_accuracy: 0.7794 - val_loss: 3.7915 - val_accuracy: 0.2774 - val_top-5-accuracy: 0.5474 - val_sparse_top_k_categorical_accuracy: 0.6554\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 5s 8ms/step - loss: 2.6633 - accuracy: 0.4108 - top-5-accuracy: 0.6886 - sparse_top_k_categorical_accuracy: 0.7808 - val_loss: 3.5357 - val_accuracy: 0.2917 - val_top-5-accuracy: 0.5603 - val_sparse_top_k_categorical_accuracy: 0.6723\n",
      "Epoch 30/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.6441 - accuracy: 0.4147 - top-5-accuracy: 0.6911 - sparse_top_k_categorical_accuracy: 0.7842 - val_loss: 3.5566 - val_accuracy: 0.2740 - val_top-5-accuracy: 0.5469 - val_sparse_top_k_categorical_accuracy: 0.6619\n",
      "Epoch 31/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.6155 - accuracy: 0.4215 - top-5-accuracy: 0.6966 - sparse_top_k_categorical_accuracy: 0.7884 - val_loss: 3.5753 - val_accuracy: 0.2863 - val_top-5-accuracy: 0.5561 - val_sparse_top_k_categorical_accuracy: 0.6659\n",
      "Epoch 32/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.5941 - accuracy: 0.4254 - top-5-accuracy: 0.7007 - sparse_top_k_categorical_accuracy: 0.7911 - val_loss: 3.5864 - val_accuracy: 0.2987 - val_top-5-accuracy: 0.5666 - val_sparse_top_k_categorical_accuracy: 0.6740\n",
      "Epoch 33/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.5772 - accuracy: 0.4283 - top-5-accuracy: 0.7033 - sparse_top_k_categorical_accuracy: 0.7956 - val_loss: 3.6797 - val_accuracy: 0.2787 - val_top-5-accuracy: 0.5464 - val_sparse_top_k_categorical_accuracy: 0.6623\n",
      "Epoch 34/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.5518 - accuracy: 0.4345 - top-5-accuracy: 0.7077 - sparse_top_k_categorical_accuracy: 0.7975 - val_loss: 3.5634 - val_accuracy: 0.2853 - val_top-5-accuracy: 0.5544 - val_sparse_top_k_categorical_accuracy: 0.6670\n",
      "Epoch 35/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.5350 - accuracy: 0.4372 - top-5-accuracy: 0.7129 - sparse_top_k_categorical_accuracy: 0.8007 - val_loss: 3.6354 - val_accuracy: 0.2932 - val_top-5-accuracy: 0.5591 - val_sparse_top_k_categorical_accuracy: 0.6667\n",
      "Epoch 36/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.5197 - accuracy: 0.4390 - top-5-accuracy: 0.7136 - sparse_top_k_categorical_accuracy: 0.8014 - val_loss: 3.6699 - val_accuracy: 0.2857 - val_top-5-accuracy: 0.5592 - val_sparse_top_k_categorical_accuracy: 0.6707\n",
      "Epoch 37/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.4924 - accuracy: 0.4436 - top-5-accuracy: 0.7177 - sparse_top_k_categorical_accuracy: 0.8061 - val_loss: 3.5516 - val_accuracy: 0.2985 - val_top-5-accuracy: 0.5684 - val_sparse_top_k_categorical_accuracy: 0.6776\n",
      "Epoch 38/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.4776 - accuracy: 0.4474 - top-5-accuracy: 0.7222 - sparse_top_k_categorical_accuracy: 0.8068 - val_loss: 3.5175 - val_accuracy: 0.2975 - val_top-5-accuracy: 0.5663 - val_sparse_top_k_categorical_accuracy: 0.6779\n",
      "Epoch 39/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.4564 - accuracy: 0.4513 - top-5-accuracy: 0.7230 - sparse_top_k_categorical_accuracy: 0.8112 - val_loss: 3.5598 - val_accuracy: 0.2992 - val_top-5-accuracy: 0.5726 - val_sparse_top_k_categorical_accuracy: 0.6837\n",
      "Epoch 40/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.4359 - accuracy: 0.4543 - top-5-accuracy: 0.7291 - sparse_top_k_categorical_accuracy: 0.8146 - val_loss: 3.7314 - val_accuracy: 0.2797 - val_top-5-accuracy: 0.5464 - val_sparse_top_k_categorical_accuracy: 0.6591\n",
      "Epoch 41/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.4179 - accuracy: 0.4580 - top-5-accuracy: 0.7322 - sparse_top_k_categorical_accuracy: 0.8165 - val_loss: 3.6559 - val_accuracy: 0.2869 - val_top-5-accuracy: 0.5604 - val_sparse_top_k_categorical_accuracy: 0.6726\n",
      "Epoch 42/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.4011 - accuracy: 0.4621 - top-5-accuracy: 0.7334 - sparse_top_k_categorical_accuracy: 0.8187 - val_loss: 3.6749 - val_accuracy: 0.2898 - val_top-5-accuracy: 0.5592 - val_sparse_top_k_categorical_accuracy: 0.6708\n",
      "Epoch 43/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.3857 - accuracy: 0.4667 - top-5-accuracy: 0.7372 - sparse_top_k_categorical_accuracy: 0.8201 - val_loss: 3.7190 - val_accuracy: 0.2755 - val_top-5-accuracy: 0.5484 - val_sparse_top_k_categorical_accuracy: 0.6593\n",
      "Epoch 44/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.3631 - accuracy: 0.4698 - top-5-accuracy: 0.7393 - sparse_top_k_categorical_accuracy: 0.8229 - val_loss: 3.6722 - val_accuracy: 0.2786 - val_top-5-accuracy: 0.5545 - val_sparse_top_k_categorical_accuracy: 0.6665\n",
      "Epoch 45/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.3507 - accuracy: 0.4722 - top-5-accuracy: 0.7428 - sparse_top_k_categorical_accuracy: 0.8256 - val_loss: 3.5403 - val_accuracy: 0.2861 - val_top-5-accuracy: 0.5554 - val_sparse_top_k_categorical_accuracy: 0.6695\n",
      "Epoch 46/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.3310 - accuracy: 0.4756 - top-5-accuracy: 0.7469 - sparse_top_k_categorical_accuracy: 0.8272 - val_loss: 3.7316 - val_accuracy: 0.2800 - val_top-5-accuracy: 0.5530 - val_sparse_top_k_categorical_accuracy: 0.6656\n",
      "Epoch 47/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.3126 - accuracy: 0.4781 - top-5-accuracy: 0.7488 - sparse_top_k_categorical_accuracy: 0.8300 - val_loss: 3.6820 - val_accuracy: 0.2889 - val_top-5-accuracy: 0.5579 - val_sparse_top_k_categorical_accuracy: 0.6733\n",
      "Epoch 48/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.2966 - accuracy: 0.4823 - top-5-accuracy: 0.7518 - sparse_top_k_categorical_accuracy: 0.8323 - val_loss: 3.7506 - val_accuracy: 0.2884 - val_top-5-accuracy: 0.5628 - val_sparse_top_k_categorical_accuracy: 0.6743\n",
      "Epoch 49/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.2804 - accuracy: 0.4863 - top-5-accuracy: 0.7546 - sparse_top_k_categorical_accuracy: 0.8348 - val_loss: 3.6131 - val_accuracy: 0.2834 - val_top-5-accuracy: 0.5545 - val_sparse_top_k_categorical_accuracy: 0.6668\n",
      "Epoch 50/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.2648 - accuracy: 0.4882 - top-5-accuracy: 0.7572 - sparse_top_k_categorical_accuracy: 0.8369 - val_loss: 3.6751 - val_accuracy: 0.2978 - val_top-5-accuracy: 0.5713 - val_sparse_top_k_categorical_accuracy: 0.6814\n",
      "Epoch 51/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.2490 - accuracy: 0.4913 - top-5-accuracy: 0.7582 - sparse_top_k_categorical_accuracy: 0.8374 - val_loss: 3.5953 - val_accuracy: 0.2886 - val_top-5-accuracy: 0.5547 - val_sparse_top_k_categorical_accuracy: 0.6700\n",
      "Epoch 52/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.2370 - accuracy: 0.4943 - top-5-accuracy: 0.7614 - sparse_top_k_categorical_accuracy: 0.8400 - val_loss: 3.7184 - val_accuracy: 0.2841 - val_top-5-accuracy: 0.5540 - val_sparse_top_k_categorical_accuracy: 0.6661\n",
      "Epoch 53/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.2223 - accuracy: 0.4967 - top-5-accuracy: 0.7636 - sparse_top_k_categorical_accuracy: 0.8416 - val_loss: 3.6794 - val_accuracy: 0.2910 - val_top-5-accuracy: 0.5642 - val_sparse_top_k_categorical_accuracy: 0.6732\n",
      "Epoch 54/80\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 2.2044 - accuracy: 0.4991 - top-5-accuracy: 0.7664 - sparse_top_k_categorical_accuracy: 0.8425 - val_loss: 3.7215 - val_accuracy: 0.2838 - val_top-5-accuracy: 0.5585 - val_sparse_top_k_categorical_accuracy: 0.6700\n",
      "Epoch 55/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1905 - accuracy: 0.5025 - top-5-accuracy: 0.7700 - sparse_top_k_categorical_accuracy: 0.8450 - val_loss: 3.6766 - val_accuracy: 0.2845 - val_top-5-accuracy: 0.5525 - val_sparse_top_k_categorical_accuracy: 0.6607\n",
      "Epoch 56/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1777 - accuracy: 0.5037 - top-5-accuracy: 0.7725 - sparse_top_k_categorical_accuracy: 0.8472 - val_loss: 3.6795 - val_accuracy: 0.2830 - val_top-5-accuracy: 0.5548 - val_sparse_top_k_categorical_accuracy: 0.6686\n",
      "Epoch 57/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1651 - accuracy: 0.5083 - top-5-accuracy: 0.7741 - sparse_top_k_categorical_accuracy: 0.8485 - val_loss: 3.6096 - val_accuracy: 0.2896 - val_top-5-accuracy: 0.5613 - val_sparse_top_k_categorical_accuracy: 0.6754\n",
      "Epoch 58/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1480 - accuracy: 0.5099 - top-5-accuracy: 0.7770 - sparse_top_k_categorical_accuracy: 0.8510 - val_loss: 3.9224 - val_accuracy: 0.2940 - val_top-5-accuracy: 0.5612 - val_sparse_top_k_categorical_accuracy: 0.6673\n",
      "Epoch 59/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1347 - accuracy: 0.5130 - top-5-accuracy: 0.7791 - sparse_top_k_categorical_accuracy: 0.8514 - val_loss: 3.8489 - val_accuracy: 0.2851 - val_top-5-accuracy: 0.5555 - val_sparse_top_k_categorical_accuracy: 0.6653\n",
      "Epoch 60/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1241 - accuracy: 0.5161 - top-5-accuracy: 0.7801 - sparse_top_k_categorical_accuracy: 0.8548 - val_loss: 3.8318 - val_accuracy: 0.2895 - val_top-5-accuracy: 0.5598 - val_sparse_top_k_categorical_accuracy: 0.6692\n",
      "Epoch 61/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.1046 - accuracy: 0.5201 - top-5-accuracy: 0.7829 - sparse_top_k_categorical_accuracy: 0.8561 - val_loss: 3.7545 - val_accuracy: 0.2915 - val_top-5-accuracy: 0.5685 - val_sparse_top_k_categorical_accuracy: 0.6786\n",
      "Epoch 62/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0933 - accuracy: 0.5213 - top-5-accuracy: 0.7834 - sparse_top_k_categorical_accuracy: 0.8577 - val_loss: 3.7987 - val_accuracy: 0.2847 - val_top-5-accuracy: 0.5559 - val_sparse_top_k_categorical_accuracy: 0.6638\n",
      "Epoch 63/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0852 - accuracy: 0.5235 - top-5-accuracy: 0.7865 - sparse_top_k_categorical_accuracy: 0.8588 - val_loss: 3.9349 - val_accuracy: 0.2741 - val_top-5-accuracy: 0.5466 - val_sparse_top_k_categorical_accuracy: 0.6604\n",
      "Epoch 64/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.0684 - accuracy: 0.5262 - top-5-accuracy: 0.7897 - sparse_top_k_categorical_accuracy: 0.8605 - val_loss: 3.7733 - val_accuracy: 0.2688 - val_top-5-accuracy: 0.5400 - val_sparse_top_k_categorical_accuracy: 0.6550\n",
      "Epoch 65/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 2.0581 - accuracy: 0.5296 - top-5-accuracy: 0.7908 - sparse_top_k_categorical_accuracy: 0.8620 - val_loss: 4.0257 - val_accuracy: 0.2768 - val_top-5-accuracy: 0.5488 - val_sparse_top_k_categorical_accuracy: 0.6632\n",
      "Epoch 66/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0469 - accuracy: 0.5297 - top-5-accuracy: 0.7923 - sparse_top_k_categorical_accuracy: 0.8639 - val_loss: 3.9411 - val_accuracy: 0.2864 - val_top-5-accuracy: 0.5622 - val_sparse_top_k_categorical_accuracy: 0.6694\n",
      "Epoch 67/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0329 - accuracy: 0.5351 - top-5-accuracy: 0.7951 - sparse_top_k_categorical_accuracy: 0.8639 - val_loss: 3.8654 - val_accuracy: 0.2845 - val_top-5-accuracy: 0.5513 - val_sparse_top_k_categorical_accuracy: 0.6630\n",
      "Epoch 68/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0179 - accuracy: 0.5370 - top-5-accuracy: 0.7974 - sparse_top_k_categorical_accuracy: 0.8671 - val_loss: 3.7839 - val_accuracy: 0.2752 - val_top-5-accuracy: 0.5479 - val_sparse_top_k_categorical_accuracy: 0.6635\n",
      "Epoch 69/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 2.0114 - accuracy: 0.5389 - top-5-accuracy: 0.7982 - sparse_top_k_categorical_accuracy: 0.8676 - val_loss: 4.0413 - val_accuracy: 0.2740 - val_top-5-accuracy: 0.5384 - val_sparse_top_k_categorical_accuracy: 0.6500\n",
      "Epoch 70/80\n",
      "591/591 [==============================] - 4s 8ms/step - loss: 1.9956 - accuracy: 0.5409 - top-5-accuracy: 0.8013 - sparse_top_k_categorical_accuracy: 0.8693 - val_loss: 3.7711 - val_accuracy: 0.2830 - val_top-5-accuracy: 0.5509 - val_sparse_top_k_categorical_accuracy: 0.6656\n",
      "Epoch 71/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9849 - accuracy: 0.5441 - top-5-accuracy: 0.8028 - sparse_top_k_categorical_accuracy: 0.8705 - val_loss: 3.8582 - val_accuracy: 0.2827 - val_top-5-accuracy: 0.5517 - val_sparse_top_k_categorical_accuracy: 0.6628\n",
      "Epoch 72/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9772 - accuracy: 0.5461 - top-5-accuracy: 0.8027 - sparse_top_k_categorical_accuracy: 0.8700 - val_loss: 3.9055 - val_accuracy: 0.2811 - val_top-5-accuracy: 0.5581 - val_sparse_top_k_categorical_accuracy: 0.6698\n",
      "Epoch 73/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9598 - accuracy: 0.5496 - top-5-accuracy: 0.8066 - sparse_top_k_categorical_accuracy: 0.8731 - val_loss: 3.8245 - val_accuracy: 0.2912 - val_top-5-accuracy: 0.5606 - val_sparse_top_k_categorical_accuracy: 0.6704\n",
      "Epoch 74/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9503 - accuracy: 0.5506 - top-5-accuracy: 0.8077 - sparse_top_k_categorical_accuracy: 0.8751 - val_loss: 3.8206 - val_accuracy: 0.2826 - val_top-5-accuracy: 0.5512 - val_sparse_top_k_categorical_accuracy: 0.6638\n",
      "Epoch 75/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9399 - accuracy: 0.5523 - top-5-accuracy: 0.8093 - sparse_top_k_categorical_accuracy: 0.8750 - val_loss: 3.8233 - val_accuracy: 0.2759 - val_top-5-accuracy: 0.5506 - val_sparse_top_k_categorical_accuracy: 0.6626\n",
      "Epoch 76/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9304 - accuracy: 0.5560 - top-5-accuracy: 0.8121 - sparse_top_k_categorical_accuracy: 0.8765 - val_loss: 4.0073 - val_accuracy: 0.2625 - val_top-5-accuracy: 0.5275 - val_sparse_top_k_categorical_accuracy: 0.6452\n",
      "Epoch 77/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9198 - accuracy: 0.5579 - top-5-accuracy: 0.8133 - sparse_top_k_categorical_accuracy: 0.8769 - val_loss: 4.0423 - val_accuracy: 0.2747 - val_top-5-accuracy: 0.5437 - val_sparse_top_k_categorical_accuracy: 0.6551\n",
      "Epoch 78/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.9018 - accuracy: 0.5611 - top-5-accuracy: 0.8166 - sparse_top_k_categorical_accuracy: 0.8805 - val_loss: 3.9459 - val_accuracy: 0.2712 - val_top-5-accuracy: 0.5437 - val_sparse_top_k_categorical_accuracy: 0.6592\n",
      "Epoch 79/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.8924 - accuracy: 0.5628 - top-5-accuracy: 0.8164 - sparse_top_k_categorical_accuracy: 0.8811 - val_loss: 4.0503 - val_accuracy: 0.2456 - val_top-5-accuracy: 0.5093 - val_sparse_top_k_categorical_accuracy: 0.6294\n",
      "Epoch 80/80\n",
      "591/591 [==============================] - 5s 8ms/step - loss: 1.8789 - accuracy: 0.5665 - top-5-accuracy: 0.8177 - sparse_top_k_categorical_accuracy: 0.8816 - val_loss: 4.0749 - val_accuracy: 0.2621 - val_top-5-accuracy: 0.5328 - val_sparse_top_k_categorical_accuracy: 0.6524\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 543, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 543, 128)     512         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 543, 64)      8256        ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 543, 64)      4160        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 543, 67)      0           ['input_2[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 543, 64)      4352        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 543, 32)      2080        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 543, 32)      1056        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 17376)        0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 250)          4344250     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,364,666\n",
      "Trainable params: 4,364,666\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if CFG.is_training:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "#     del X, y\n",
    "    gc.collect()\n",
    "    model = get_model()\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(\"model.h5\")]\n",
    "    model.fit(X_train, y_train, epochs=80, validation_data=(X_val, y_val), batch_size=128, callbacks=callbacks)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"../model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b31b507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:46:18.662320Z",
     "start_time": "2023-02-27T20:46:17.730810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: temp/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e7fd95f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:00:56.205957Z",
     "start_time": "2023-02-27T21:00:49.689152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362/2362 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39688, 0.5251055159365449)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(model.predict(X_train),axis=1)\n",
    "corr = sum(preds == y_train)\n",
    "corr, corr/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3999c2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:49:36.410831Z",
     "start_time": "2023-02-27T20:49:36.408142Z"
    }
   },
   "outputs": [],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_saved_model('temp/') # path to the SavedModel directory\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "# with open('model.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb2322b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T20:49:57.087106Z",
     "start_time": "2023-02-27T20:49:55.241114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpi1nccvc4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:49:56.670859: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-02-27 12:49:56.670898: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-02-27 12:49:56.671049: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpi1nccvc4\n",
      "2023-02-27 12:49:56.673294: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-27 12:49:56.673309: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpi1nccvc4\n",
      "2023-02-27 12:49:56.680011: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-02-27 12:49:56.743934: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpi1nccvc4\n",
      "2023-02-27 12:49:56.756675: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 85627 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c308937a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:11:36.930067Z",
     "start_time": "2023-02-27T21:11:36.926063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <keras.layers.core.dense.Dense object at 0x7f3ae055e550>\n",
      "2 <keras.layers.core.dense.Dense object at 0x7f3ae055e5e0>\n",
      "3 <keras.layers.core.dense.Dense object at 0x7f3ae055e940>\n",
      "4 <keras.layers.merging.concatenate.Concatenate object at 0x7f3ae011c880>\n",
      "5 <keras.layers.core.dense.Dense object at 0x7f3ae031b250>\n",
      "6 <keras.layers.core.dense.Dense object at 0x7f3b8044f880>\n",
      "7 <keras.layers.core.dense.Dense object at 0x7f3b94089ee0>\n",
      "8 <keras.layers.reshaping.flatten.Flatten object at 0x7f3c0419de50>\n",
      "9 <keras.layers.core.dense.Dense object at 0x7f3ae00fa070>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(model.layers)): print(i, model.layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55690f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:12:45.697330Z",
     "start_time": "2023-02-27T21:12:45.689440Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inference_model(model):\n",
    "    inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "    x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "    x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "    \n",
    "    h1 = model.layers[1](x)\n",
    "    h2 = model.layers[2](h1)\n",
    "    h3 = model.layers[3](h2)\n",
    "    \n",
    "    concat = model.layers[4]([x, h3])\n",
    "    vector = model.layers[5](concat)\n",
    "    vector = model.layers[6](vector)\n",
    "    vector = model.layers[7](vector)\n",
    "    vector = model.layers[8](vector)\n",
    "    x = model.layers[9](vector)\n",
    "    \n",
    "    output = tf.keras.layers.Activation(activation=\"linear\", name=\"outputs\")(x)\n",
    "    inference_model = tf.keras.Model(inputs=inputs, outputs=output) \n",
    "    inference_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f296dde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:12:46.724856Z",
     "start_time": "2023-02-27T21:12:46.721903Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_inference_model(model):\n",
    "#     inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "#     x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "#     x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "#     for i in range(1, len(model.layers)):\n",
    "#         x = model.layers[i](x)\n",
    "    \n",
    "#     output = tf.keras.layers.Activation(activation=\"linear\", name=\"outputs\")(x)\n",
    "#     inference_model = tf.keras.Model(inputs=inputs, outputs=output) \n",
    "#     inference_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "#     return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f14a893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:12:47.350275Z",
     "start_time": "2023-02-27T21:12:47.253218Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 543, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.math.is_nan_2 (TFOpLambda)  (None, 543, 3)       0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.zeros_like_2 (TFOpLambda)   (None, 543, 3)       0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.where_2 (TFOpLambda)        (None, 543, 3)       0           ['tf.math.is_nan_2[0][0]',       \n",
      "                                                                  'tf.zeros_like_2[0][0]',        \n",
      "                                                                  'inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (1, 543, 3)         0           ['tf.where_2[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                multiple             512         ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                multiple             8256        ['dense_7[2][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                multiple             4160        ['dense_8[2][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    multiple             0           ['tf.math.reduce_mean_2[0][0]',  \n",
      "                                                                  'dense_9[2][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               multiple             4352        ['concatenate_1[2][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               multiple             2080        ['dense_10[1][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               multiple             1056        ['dense_11[1][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            multiple             0           ['dense_12[1][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               multiple             4344250     ['flatten_1[1][0]']              \n",
      "                                                                                                  \n",
      " outputs (Activation)           (1, 250)             0           ['dense_13[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,364,666\n",
      "Trainable params: 4,364,666\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model = get_inference_model(model)\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f085dbd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:12:52.737440Z",
     "start_time": "2023-02-27T21:12:51.616378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6z18gb2w/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6z18gb2w/assets\n",
      "2023-02-27 13:12:52.422873: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-02-27 13:12:52.422909: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-02-27 13:12:52.423057: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp6z18gb2w\n",
      "2023-02-27 13:12:52.424368: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-27 13:12:52.424384: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp6z18gb2w\n",
      "2023-02-27 13:12:52.427795: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-02-27 13:12:52.460475: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp6z18gb2w\n",
      "2023-02-27 13:12:52.467094: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 44038 microseconds.\n",
      "2023-02-27 13:12:52.589708: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 30.668 M  ops, equivalently 15.334 M  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n",
    "tflite_model = converter.convert()\n",
    "model_path = \"model.tflite\"\n",
    "# Save the model.\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a86d848c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:21:31.573075Z",
     "start_time": "2023-02-27T21:13:59.405757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 94477/94477 [07:32<00:00, 208.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tflite.Interpreter(model_path)\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "corr = 0\n",
    "wrong = []\n",
    "for i in tqdm(range(len(train))):\n",
    "    frames = load_relevant_data_subset(f'../{train.iloc[i].path}')\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    sign = np.argmax(output[\"outputs\"])\n",
    "    if index_label[sign] == train.iloc[i].sign:\n",
    "        corr += 1\n",
    "    else:\n",
    "        wrong.append((index_label[sign], train.iloc[i].sign, train.iloc[i].path))\n",
    "\n",
    "    #     print(f\"Predicted label: {index_label[sign]}, Actual Label: {train.iloc[i].sign}\")\n",
    "\n",
    "\n",
    "    total = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "208c7c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:21:31.577845Z",
     "start_time": "2023-02-27T21:21:31.574769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total=94476\n",
      "corr=45869\t Percent: 48.550955%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = f'''\n",
    "{total=}\n",
    "{corr=}\\t Percent: {corr/total:%}\n",
    "'''\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cefcc39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T21:21:31.622685Z",
     "start_time": "2023-02-27T21:21:31.578892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airplane</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>sick</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>pig</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>shoe</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>wait</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>563</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>pool</td>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>look</td>\n",
       "      <td>666</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after</td>\n",
       "      <td>721</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>open</td>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred  true  path\n",
       "2    airplane    37    37\n",
       "198      sick    41    41\n",
       "171       pig    43    43\n",
       "196      shoe    44    44\n",
       "232      wait    45    45\n",
       "..        ...   ...   ...\n",
       "3         all   563   563\n",
       "175      pool   663   663\n",
       "136      look   666   666\n",
       "1       after   721   721\n",
       "161      open   785   785\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongs = pd.DataFrame(data=wrong, columns=['pred','true','path'])\n",
    "wrongs.groupby('pred').count().reset_index().sort_values('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
