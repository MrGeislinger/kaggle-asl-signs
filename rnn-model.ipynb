{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0ff53c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:33.327206Z",
     "start_time": "2023-03-05T05:46:31.389025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 21:46:31.670106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 21:46:31.815544: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-04 21:46:32.264009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-03-04 21:46:32.264071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-03-04 21:46:32.264075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c7db3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:33.391207Z",
     "start_time": "2023-03-05T05:46:33.329008Z"
    },
    "code_folding": [
     7,
     15,
     23,
     30
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 94477 rows, 4 cols\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path('..')\n",
    "DF_TRAIN = DATA_ROOT / 'train.csv'\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    data_path = \"../\"\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cafb3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:33.470869Z",
     "start_time": "2023-03-05T05:46:33.392868Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d86fd02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:33.477507Z",
     "start_time": "2023-03-05T05:46:33.472907Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_frames(\n",
    "    frames_data,\n",
    "    max_frames: int = 20,\n",
    "    crop_method: str = 'nearest',\n",
    "    get_masks: bool = True,\n",
    "):\n",
    "    '''Take frames data shape=(n_frames, pts, dims) to fixed num of frames.\n",
    "    \n",
    "    - Pads data with fewer frames with zeros\n",
    "    - Reduces max number of allowed frames by crop method:\n",
    "        * 'nearest' (default): \n",
    "    '''\n",
    "    \n",
    "    if len(frames_data) < max_frames:\n",
    "        diff = max_frames - len(frames_data)\n",
    "        padding = np.zeros((diff, 543, 3))\n",
    "        frames = np.concatenate((frames_data, padding))\n",
    "        if get_masks:\n",
    "            # Only mask the padding\n",
    "            masks = np.zeros(shape=(1, max_frames,), dtype='bool')\n",
    "            masks[0,:len(frames_data)] = 1\n",
    "            \n",
    "    else:\n",
    "        if crop_method == 'nearest':\n",
    "            frames = tf.image.resize(\n",
    "                frames_data,\n",
    "                (max_frames, 543),\n",
    "                method='nearest',\n",
    "            ).numpy()\n",
    "        elif crop_method == 'cut':\n",
    "            frames = frames_data[:max_frames]\n",
    "        else:\n",
    "            raise Exception(f'{crop_method=} not found')\n",
    "        if get_masks:\n",
    "            # Use all the frames\n",
    "            masks = np.ones(shape=(1, max_frames,), dtype='bool')\n",
    "\n",
    "    if get_masks:\n",
    "        return frames, masks\n",
    "    else:\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bc36c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:33.493076Z",
     "start_time": "2023-03-05T05:46:33.478377Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compress_frames(frames):\n",
    "    '''Make a video of shape (n_frames, pts, dims) --> (n_frames, pts*dims) '''\n",
    "    n_frames = frames.shape[0]\n",
    "    columns = frames.shape[1]*frames.shape[2]\n",
    "    return frames.reshape(n_frames, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0304415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:38.018884Z",
     "start_time": "2023-03-05T05:46:33.494039Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94477, 20, 1629) (94477,)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "MAX_FRAMES = 20\n",
    "MAX_SEQ_LENGTH = MAX_FRAMES\n",
    "N_PTS = 543\n",
    "N_DIMS = 3\n",
    "NUM_FEATURES = N_PTS*N_DIMS\n",
    "\n",
    "X_npy_fname = f'X-{MAX_FRAMES}_frames-pts_flattened.npy'\n",
    "y_npy_fname = f'y.npy'\n",
    "masks_fname = f'all_masks-{MAX_FRAMES}.npy'\n",
    "\n",
    "if CFG.is_training:\n",
    "    try:\n",
    "        X = np.load(X_npy_fname)\n",
    "        All_masks = np.load(masks_fname)\n",
    "        y = np.load(y_npy_fname)\n",
    "    except:\n",
    "        X = np.zeros((len(train), MAX_FRAMES, N_PTS*N_DIMS))\n",
    "        All_masks = np.zeros(shape=(len(train), MAX_FRAMES), dtype='bool')\n",
    "        y = np.zeros((len(train),))\n",
    "        num_frames = np.zeros(len(train))\n",
    "        for i in tqdm(range(len(train))):\n",
    "            path = f\"{CFG.data_path}{train.iloc[i].path}\"\n",
    "            data = load_relevant_data_subset_with_imputation(path)\n",
    "            ## Mean Aggregation\n",
    "            frames_reduced, masks = load_frames(data, max_frames=MAX_FRAMES)\n",
    "            data_resize = compress_frames(frames_reduced)\n",
    "            X[i] = data_resize\n",
    "            All_masks[i] = masks\n",
    "            y[i] = train.iloc[i].label\n",
    "            num_frames[i] = data.shape[0]\n",
    "        ## Save number of frames of each training sample for data analysis\n",
    "        train['num_frames'] = num_frames\n",
    "        print(train['num_frames'].describe())\n",
    "        train.to_csv('train.csv', index=False)\n",
    "        np.save(X_npy_fname, X)\n",
    "        np.save(y_npy_fname, y)\n",
    "        np.save(masks_fname, All_masks)\n",
    "\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a5993c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:38.026787Z",
     "start_time": "2023-03-05T05:46:38.020382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94477, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401be3ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:38.045450Z",
     "start_time": "2023-03-05T05:46:38.027834Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Make All_masks as part of split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "# print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba54c41",
   "metadata": {},
   "source": [
    "# RNN Model\n",
    "\n",
    "> https://keras.io/examples/vision/video_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d99167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:38.055901Z",
     "start_time": "2023-03-05T05:46:38.046561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility for our sequence model.\n",
    "def get_sequence_model(max_frames: int, num_features: int):\n",
    "    n_classes = 250\n",
    "\n",
    "    frame_features_input = tf.keras.Input((max_frames, num_features))\n",
    "    mask_input = tf.keras.Input((max_frames,), dtype='bool')\n",
    "\n",
    "    # Why `mask`: https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = tf.keras.layers.GRU(64, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = tf.keras.layers.GRU(64)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    rnn_model = tf.keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8289a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:38.071243Z",
     "start_time": "2023-03-05T05:46:38.057965Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    validation_data = None,\n",
    "    validation_split: int = 0.2,\n",
    "    model_path: str = 'temp',\n",
    "    epochs: int = 10,\n",
    "    batch_size: int = 128,\n",
    "    monitor_metric: str = 'val_accuracy',\n",
    "    patience: int = 6,\n",
    "):\n",
    "    print(model.summary())\n",
    "    checkpoint = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            model_path,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ]\n",
    "        \n",
    "    fit_params = dict(\n",
    "        x=train_data,\n",
    "        y=train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    if validation_data:\n",
    "        fit_params['validation_data'] = validation_data\n",
    "    else:\n",
    "        fit_params['validation_split'] = validation_split\n",
    "\n",
    "    history = model.fit(\n",
    "        **fit_params,\n",
    "        callbacks=checkpoint,\n",
    "    )\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "    _, accuracy = model.evaluate(X_val, y_val)\n",
    "    print(f'Validation accuracy: {accuracy:.2%}')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa7ae1",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dc5378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:39.732435Z",
     "start_time": "2023-03-05T05:46:38.072559Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 21:46:38.162673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.169598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.169866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.170525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 21:46:38.173805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.174051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.174265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.549812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.550008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.550145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-04 21:46:38.550262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21932 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = get_sequence_model(max_frames=MAX_FRAMES, num_features=NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c21d6df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T05:46:39.746660Z",
     "start_time": "2023-03-05T05:46:39.733896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20, 1629)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 20, 64)       325440      ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 64)           24960       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           4160        ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 250)          16250       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 370,810\n",
      "Trainable params: 370,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a692f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-05T05:46:31.353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20, 1629)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 20, 64)       325440      ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 64)           24960       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           4160        ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 250)          16250       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 370,810\n",
      "Trainable params: 370,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 21:46:41.677289: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 9849715920 exceeds 10% of free system memory.\n",
      "2023-03-04 21:46:46.020495: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 9849715920 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 21:46:52.557868: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2023-03-04 21:46:53.197203: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-04 21:46:53.941424: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 609/2362 [======>.......................] - ETA: 17s - loss: 5.5234 - accuracy: 0.0033"
     ]
    }
   ],
   "source": [
    "model, history = run_experiment(\n",
    "    model=model,\n",
    "    train_data=[X, All_masks],\n",
    "    train_labels=y,\n",
    "    validation_split=0.2,\n",
    "    model_path='model_test-rnn.h5',\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    patience=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97a6ba",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13752abc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-05T05:46:31.354Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "141px",
    "width": "317px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
