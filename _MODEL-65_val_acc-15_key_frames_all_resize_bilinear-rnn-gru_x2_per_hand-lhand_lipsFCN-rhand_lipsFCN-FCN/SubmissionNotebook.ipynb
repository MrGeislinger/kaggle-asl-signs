{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c2b77e-51cb-4d95-90b5-4d8d855c3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 12:56:22.610847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 12:56:25.300932: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-10 12:56:29.263717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/maxpow/miniconda3/envs/tf/lib/:/home/maxpow/miniconda3/envs/tf/lib/\n",
      "2023-03-10 12:56:29.263803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/maxpow/miniconda3/envs/tf/lib/:/home/maxpow/miniconda3/envs/tf/lib/\n",
      "2023-03-10 12:56:29.263809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_preprocess import get_key_frames_by_cluster\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec514217-f1cf-4c10-9e03-89953bb748df",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a7d5b2-33da-45c0-aa8e-e5f5a77b632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DIR='/home/maxpow/Workspace/kaggle-asl/kaggle-asl-signs'\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "mirror = True\n",
    "MAX_FRAMES = 15\n",
    "MAX_SEQ_LENGTH = MAX_FRAMES\n",
    "N_PTS = 543\n",
    "N_DIMS = 2\n",
    "NUM_FEATURES = N_PTS*N_DIMS\n",
    "\n",
    "START_FACE, END_FACE = (0, 468)\n",
    "START_LHAND, END_LHAND = (468, 489)\n",
    "START_POSE, END_POSE = (489, 522)\n",
    "START_RHAND, END_RHAND = (522, 543)\n",
    "LIPS_PTS = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "\n",
    "PATIENCE = 16\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500\n",
    "\n",
    "LR_START = 0.001\n",
    "REDUCE_LR_PATIENCE = 4\n",
    "REDUCE_LR_FACTOR = 0.2\n",
    "\n",
    "X_npy_fname = f'X-all-{MAX_FRAMES:02}_frames_key_resize_bilinear.npy'\n",
    "y_npy_fname = f'y.npy'\n",
    "\n",
    "COMP = os.environ.get('COMP_NAME', '?')\n",
    "__file__ = os.path.abspath('')\n",
    "MODEL_DIR = '/'.join((__file__).split('/')[:-1])\n",
    "print(f'{MODEL_DIR=}')\n",
    "METRIC_STR = '_xx_val_acc-'\n",
    "MODEL_NAME = MODEL_DIR.split(METRIC_STR)[-1]\n",
    "\n",
    "model_details = (\n",
    "    f'{MODEL_NAME}'\n",
    "    f'-key_frames_all_resize_bilinear'\n",
    "    f'-{MAX_FRAMES:02}_frames'\n",
    "    f'-{N_PTS}_pts_per_frame'\n",
    "    f'-{N_DIMS}_dims'\n",
    "    f'-mirror' if mirror else ''\n",
    "    f'-{BATCH_SIZE}_batch_size'\n",
    ")\n",
    "\n",
    "DATA_ROOT = '../data/'\n",
    "DF_TRAIN =  f'{DATA_ROOT}train.csv'\n",
    "\n",
    "# train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b44cd3-4d81-46d0-bc16-71c5f0e1f1f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290e04b-f37a-48ba-9e8b-6470d8d89437",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08be54ba-971f-4af7-af96-968de7fd0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = DATA_ROOT\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4986f7-6200-4077-990c-8554771c8c18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start pre-processing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30614e4a-7ee3-455d-9db9-32680f359c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.is_training:\n",
    "    try:\n",
    "        X = np.load(X_npy_fname)\n",
    "        y = np.load(y_npy_fname)\n",
    "    except:\n",
    "        X = np.zeros((len(train), MAX_FRAMES, NUM_FEATURES))\n",
    "        y = np.zeros((len(train),))\n",
    "        for i in tqdm(range(len(train))):\n",
    "            y[i] = train.iloc[i].label\n",
    "            path = f'{CFG.data_path}{train.iloc[i].path}'\n",
    "            data = load_relevant_data_subset_with_imputation(path)\n",
    "            hands_mask = np.zeros(data.shape[1], dtype='bool')\n",
    "            hands_mask[START_LHAND:END_LHAND] = True # LHAND\n",
    "            hands_mask[START_RHAND:END_RHAND] = True # RHAND\n",
    "            #\n",
    "            ## Frame Aggregation\n",
    "            data_key_frames = tf.image.resize(\n",
    "                data[:,:,:N_DIMS],\n",
    "                size=(MAX_FRAMES, N_PTS),\n",
    "                method='bilinear', #DEFAULT\n",
    "            )\n",
    "            n_frames = data_key_frames.shape[0]\n",
    "            columns = data_key_frames.shape[1]*data_key_frames.shape[2]\n",
    "            data_resize = tf.reshape(\n",
    "                tensor=data_key_frames,\n",
    "                shape=(n_frames, columns),\n",
    "            )\n",
    "            X[i] = data_resize\n",
    "            y[i] = train.iloc[i].label\n",
    "        # Save number of frames of each training sample for data analysis\n",
    "        np.save(X_npy_fname, X)\n",
    "        np.save(y_npy_fname, y)\n",
    "\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=27,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "# Double the training data by mirroring the coordinates over the x-axis\n",
    "if mirror:\n",
    "    # Mirror x-axis of features\n",
    "    X_temp = np.zeros(\n",
    "        shape=(X_train.shape[0]*2, *X_train.shape[1:]),\n",
    "    )\n",
    "    X_temp[:X_train.shape[0]] = X_train\n",
    "    X_temp[X_train.shape[0]:] = X_train\n",
    "    X_temp[X_train.shape[0]:,:,0] *= -1 \n",
    "    X_train = X_temp\n",
    "    #\n",
    "    y_temp = np.zeros(\n",
    "        shape=(y_train.shape[0]*2,),\n",
    "    )\n",
    "    y_temp[:y_train.shape[0]] = y_train\n",
    "    y_temp[y_train.shape[0]:] = y_train\n",
    "    y_train = y_temp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f885b0f-af0a-4b53-a209-1831853ee389",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89eb0806-3d3c-4fe2-aa74-230fcf5f3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RNN Model \n",
    "# > https://keras.io/examples/vision/video_classification/\n",
    "\n",
    "# Utility for our sequence model.\n",
    "def get_sequence_model(max_frames: int, num_features: int):\n",
    "    n_classes = 250\n",
    "\n",
    "    frame_features_input = tf.keras.Input((max_frames, num_features))\n",
    "\n",
    "    # Data's dimensions were flattened so need to get the relevant pieces\n",
    "    input_lhand = tf.keras.layers.Lambda(\n",
    "        lambda x: x[:, :, START_LHAND*N_DIMS:END_LHAND*N_DIMS],\n",
    "        output_shape=(MAX_FRAMES, (END_LHAND - START_LHAND), N_DIMS),\n",
    "    )(frame_features_input)\n",
    "    input_rhand = tf.keras.layers.Lambda(\n",
    "        lambda x: x[:, :, START_RHAND*N_DIMS:END_RHAND*N_DIMS],\n",
    "        output_shape=(MAX_FRAMES, (END_RHAND - START_RHAND), N_DIMS),\n",
    "    )(frame_features_input)\n",
    "    input_lips = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.gather(x, LIPS_PTS, axis=2),\n",
    "        output_shape=(MAX_FRAMES, len(LIPS_PTS), N_DIMS),\n",
    "    )(frame_features_input)\n",
    "    \n",
    "    ## RNN\n",
    "\n",
    "    ## lhand + lips\n",
    "    concat_lhand = tf.keras.layers.Concatenate()([input_lhand, input_lips])\n",
    "    l = tf.keras.layers.GRU(128, return_sequences=True)(concat_lhand)\n",
    "    l = tf.keras.layers.GRU(64)(l)\n",
    "    # FCN\n",
    "    l = tf.keras.layers.Dense(256)(l)\n",
    "    l = tf.keras.layers.BatchNormalization()(l)\n",
    "    l = tf.keras.layers.Activation('relu')(l)\n",
    "    l = tf.keras.layers.Dropout(0.2)(l)\n",
    "    l = tf.keras.layers.Dense(128)(l)\n",
    "    l = tf.keras.layers.BatchNormalization()(l)\n",
    "    l = tf.keras.layers.Activation('relu')(l)\n",
    "    l = tf.keras.layers.Dropout(0.2)(l)\n",
    "\n",
    "    ## rhand\n",
    "    concat_rhand = tf.keras.layers.Concatenate()([input_rhand, input_lips])\n",
    "    r = tf.keras.layers.GRU(128, return_sequences=True)(concat_rhand)\n",
    "    r = tf.keras.layers.GRU(64)(r)\n",
    "    # FCN\n",
    "    r = tf.keras.layers.Dense(256)(r)\n",
    "    r = tf.keras.layers.BatchNormalization()(r)\n",
    "    r = tf.keras.layers.Activation('relu')(r)\n",
    "    r = tf.keras.layers.Dropout(0.2)(r)\n",
    "    r = tf.keras.layers.Dense(128)(r)\n",
    "    r = tf.keras.layers.BatchNormalization()(r)\n",
    "    r = tf.keras.layers.Activation('relu')(r)\n",
    "    r = tf.keras.layers.Dropout(0.2)(r)\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    concat_hands = tf.keras.layers.Concatenate()([l, r])\n",
    "    x = tf.keras.layers.Dense(128)(concat_hands)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "   \n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    rnn_model = tf.keras.Model([frame_features_input,], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Nadam(\n",
    "            learning_rate=LR_START,\n",
    "        ),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return rnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831c5667-f97b-4f2c-9a74-0adcb57bb64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 13:04:06.622085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:07.227940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:07.228261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:07.235676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 13:04:07.236754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:07.237044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:07.237306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:10.185886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:10.189307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:10.189459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-10 13:04:10.189569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9301 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15, 1086)]   0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 15, 42)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 15, 40)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 15, 42)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 15, 82)       0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 15, 82)       0           ['lambda_1[0][0]',               \n",
      "                                                                  'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 15, 128)      81408       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 15, 128)      81408       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 64)           37248       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 64)           37248       ['gru_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          16640       ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          16640       ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256)         1024        ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256)         1024        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128)         512         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          32896       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64)          256         ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64)           0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 250)          16250       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 401,786\n",
      "Trainable params: 399,866\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_sequence_model(max_frames=MAX_FRAMES, num_features=NUM_FEATURES)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffab338-12e0-4c38-95a1-ac64e75a7dad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8313436-3565-4252-a919-ae88a97fd0f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5625-85a9-4d77-a6df-aaeffb5ee68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    validation_data = None,\n",
    "    validation_split: int = 0.2,\n",
    "    model_path: str = 'temp',\n",
    "    epochs: int = 10,\n",
    "    batch_size: int = 128,\n",
    "    monitor_metric: str = 'val_accuracy',\n",
    "    patience: int = 6,\n",
    "):\n",
    "    from Slack import SlackCallback\n",
    "    slack_callback = SlackCallback(\n",
    "        token=os.environ['SLACK_BOT_TOKEN'],\n",
    "        start_message=(\n",
    "            f'Model starting on {COMP=} for {EPOCHS=}\\n'\n",
    "            f'{model_details=}'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            model_path,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=(\n",
    "                'logs/fit/'\n",
    "                + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                + f'-{model_details}'\n",
    "            ),\n",
    "            histogram_freq=1,\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=REDUCE_LR_FACTOR,\n",
    "            patience=REDUCE_LR_PATIENCE,\n",
    "        ),\n",
    "        slack_callback,\n",
    "    ]\n",
    "        \n",
    "    fit_params = dict(\n",
    "        x=train_data,\n",
    "        y=train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    if validation_data:\n",
    "        fit_params['validation_data'] = validation_data\n",
    "    else:\n",
    "        fit_params['validation_split'] = validation_split\n",
    "\n",
    "    history = model.fit(\n",
    "        **fit_params,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0b266-8f2b-48e6-b0d1-9b6dd72407db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0ec61-27c4-4233-9565-ecb1d6d3c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Experiment\n",
    "model_details += f'-{model.count_params()}_model_params'\n",
    "model, history = run_experiment(\n",
    "    model=model,\n",
    "    train_data=(X_train,),\n",
    "    train_labels=y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    model_path=f'{MODEL_DIR}/model-{model_details}.h5',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    ")\n",
    "\n",
    "joblib.dump(history, f'{MODEL_DIR}/history-{model_details}.gz')\n",
    "\n",
    "\n",
    "# Plot Results\n",
    "# summarize history for accuracy\n",
    "fig, (ax_acc, ax_loss) = plt.subplots(ncols=2, figsize=(16,12))\n",
    "\n",
    "ax_acc.plot(history.history['accuracy'])\n",
    "ax_acc.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "ax_loss.plot(history.history['loss'])\n",
    "ax_loss.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "fig.savefig(f'{MODEL_DIR}/acc_loss-{model_details}.png')\n",
    "results = model.evaluate(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "val_loss, val_acc = results\n",
    "print(f'{val_loss=}')\n",
    "print(f'{val_acc*100:2.0f}_val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd5dc1f-a32c-4544-9c38-980f5820bdb9",
   "metadata": {},
   "source": [
    "## Generate TFlite Model for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c609cc6d-0d13-45e8-ad78-d8625371a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15, 1086)]   0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 15, 42)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 15, 40)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 15, 42)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 15, 82)       0           ['lambda[0][0]',                 \n",
      "                                                                  'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 15, 82)       0           ['lambda_1[0][0]',               \n",
      "                                                                  'lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 15, 128)      81408       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    (None, 15, 128)      81408       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 64)           37248       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 64)           37248       ['gru_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          16640       ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          16640       ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256)         1024        ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256)         1024        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128)         512         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          32896       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64)          256         ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64)           0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 250)          16250       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 401,786\n",
      "Trainable params: 399,866\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model weights\n",
    "model_weights_path = 'model-15_key_frames_all_resize_bilinear-rnn-gru_x2_per_hand-lhand_lipsFCN-rhand_lipsFCN-FCN-key_frames_all_resize_bilinear-15_frames-543_pts_per_frame-2_dims-mirror-401786_model_params.h5'\n",
    "model.load_weights(model_weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cca06a9-34d9-4489-b939-25f6e9711f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.49620017  0.38049233  0.4951877  ...  0.3944272   0.39395487\n",
      "    0.3962465 ]\n",
      "  [ 0.49900684  0.37970504  0.49199703 ...  0.3782073   0.43454036\n",
      "    0.3804755 ]\n",
      "  [ 0.50687355  0.37971362  0.49867222 ...  0.3828612   0.4434531\n",
      "    0.38227323]\n",
      "  ...\n",
      "  [ 0.5368115   0.37657106  0.53786635 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5357693   0.37589476  0.53675437 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5362242   0.37557045  0.5357279  ...  0.4721193  -0.02332834\n",
      "    0.45985666]]], shape=(1, 15, 1086), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class FeatureGen(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "    \n",
    "    def call(self, x_in):\n",
    "        \"\"\"\n",
    "        Given x_in of shape (n, 543, 3), return a new x which uses 15 key_frames so the shape would be (1, 15, 543*2)\n",
    "        \"\"\"\n",
    "        N_PTS = 543\n",
    "        N_DIMS = 2\n",
    "        MAX_FRAMES = 15\n",
    "        # x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "        x_in = tf.where(tf.math.is_nan(x_in), tf.zeros_like(x_in), x_in)\n",
    "        \n",
    "        data_key_frames = tf.image.resize(\n",
    "            images=x_in[:, :, :N_DIMS],\n",
    "            size=(MAX_FRAMES, N_PTS),\n",
    "            method='bilinear',\n",
    "        )\n",
    "        \n",
    "        n_frames = data_key_frames.shape[0]\n",
    "        columns = data_key_frames.shape[1]*data_key_frames.shape[2]\n",
    "        x_out = tf.reshape(\n",
    "            tensor=data_key_frames,\n",
    "            shape=(n_frames, columns),\n",
    "        )\n",
    "        \n",
    "        return tf.expand_dims(x_out, axis=0)\n",
    "\n",
    "print(FeatureGen()(load_relevant_data_subset(f'{CFG.data_path}{train.iloc[0].path}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d46e7b94-f3be-418e-abd4-02a00b1545dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLiteModel(tf.Module):\n",
    "    \"\"\"\n",
    "    TensorFlow Lite model that takes input tensors and applies:\n",
    "        – a preprocessing model\n",
    "        – the ASL model \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, asl_model):\n",
    "        \"\"\"\n",
    "        Initializes the TFLiteModel with the specified feature generation model and main model.\n",
    "        \"\"\"\n",
    "        super(TFLiteModel, self).__init__()\n",
    "\n",
    "        # Load the feature generation and main models\n",
    "        self.prep_inputs = FeatureGen()\n",
    "        self.asl_model   = asl_model\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        Applies the feature generation model and main model to the input tensors.\n",
    "\n",
    "        Args:\n",
    "            inputs: Input tensor with shape [num_frames, 543, 3].\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with a single key 'outputs' and corresponding output tensor.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n",
    "        outputs = self.asl_model(x)\n",
    "\n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "889062c0-2cda-4aff-a310-1427b4bd0119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 1086)\n",
      "blow\n",
      "blow\n"
     ]
    }
   ],
   "source": [
    "tflite_keras_model = TFLiteModel(asl_model=model)\n",
    "prediction = tflite_keras_model(load_relevant_data_subset(f'{CFG.data_path}{train.iloc[0].path}'))[\"outputs\"]\n",
    "\n",
    "print(index_label[tf.argmax(prediction, axis=1).numpy()[0]])\n",
    "print(f'{train.iloc[0].sign}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4f83dba-14c5-425d-8e56-6c05b391502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 1086)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as feature_gen_69_layer_call_fn, feature_gen_69_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdteiafun/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdteiafun/assets\n",
      "2023-03-10 14:21:33.548512: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-10 14:21:33.548532: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-10 14:21:33.549033: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpdteiafun\n",
      "2023-03-10 14:21:33.569074: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-10 14:21:33.569093: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpdteiafun\n",
      "2023-03-10 14:21:33.665172: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-10 14:21:33.700031: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-10 14:21:33.869552: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpdteiafun\n",
      "2023-03-10 14:21:33.987760: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 438728 microseconds.\n",
      "2023-03-10 14:21:34.503210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-10 14:21:35.056152: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 0.885 M  ops, equivalently 0.443 M  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n",
    "tflite_model = keras_model_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da6638e9-bd13-4322-9fc6-f2fc51b47634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model.tflite\"\n",
    "# Save the model.\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14f83562-b64e-4a3c-8b4f-71e56d506932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:11<00:00, 86.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tflite.Interpreter(model_path)\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "for i in tqdm(range(100)):\n",
    "    # frames = load_relevant_data_subset(f'/kaggle/input/asl-signs/{train.iloc[i].path}')\n",
    "    frames = load_relevant_data_subset(f'{CFG.data_path}{train.iloc[i].path}')\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    sign = np.argmax(output[\"outputs\"])\n",
    "    # print(f\"Predicted label: {index_label[sign]}, Actual Label: {train.iloc[i].sign}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f0ef9-4a05-473b-bbd7-d6641f03fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('submission.zip', mode='w').write('model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1074e3e-f183-4e9d-bc73-debbda831285",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/kaggle/working/models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "!zip submission.zip /kaggle/working/models/model.tflite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
