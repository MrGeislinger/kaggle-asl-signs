{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aceb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.389432Z",
     "start_time": "2023-03-04T05:57:24.607977Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc203fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.395867Z",
     "start_time": "2023-03-04T05:57:36.391979Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import imageio\n",
    "# import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa432e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.415836Z",
     "start_time": "2023-03-04T05:57:36.397607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 1024\n",
    "IMG_SIZE = 128\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeeffe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.516721Z",
     "start_time": "2023-03-04T05:57:36.417343Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path('..')\n",
    "DF_TRAIN = DATA_ROOT / 'train.csv'\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    data_path = \"../\"\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe1796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.595149Z",
     "start_time": "2023-03-04T05:57:36.518828Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716dd6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.608018Z",
     "start_time": "2023-03-04T05:57:36.596550Z"
    }
   },
   "outputs": [],
   "source": [
    "path = f\"{CFG.data_path}{train.iloc[0].path}\"\n",
    "data0 = load_relevant_data_subset_with_imputation(path)\n",
    "path = f\"{CFG.data_path}{train.iloc[1].path}\"\n",
    "data1 = load_relevant_data_subset_with_imputation(path)\n",
    "\n",
    "\n",
    "data0.shape, data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18e3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.612506Z",
     "start_time": "2023-03-04T05:57:36.609266Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_frames(\n",
    "    frames_data,\n",
    "    max_frames: int = MAX_SEQ_LENGTH,\n",
    "    crop_method: str = 'nearest',\n",
    "):\n",
    "    '''Take frames data shape=(n_frames, pts, dims) to fixed num of frames.\n",
    "    \n",
    "    - Pads data with fewer frames with zeros\n",
    "    - Reduces max number of allowed frames by crop method:\n",
    "        * 'nearest' (default): \n",
    "    '''\n",
    "    if len(frames_data) < max_frames:\n",
    "        diff = max_frames - len(frames_data)\n",
    "        padding = np.zeros((diff, 543, 3))\n",
    "        frames = np.concatenate((frames_data, padding))\n",
    "    else:\n",
    "        if crop_method == 'nearest':\n",
    "            frames = tf.image.resize(\n",
    "                frames_data,\n",
    "                (max_frames, 543),\n",
    "                method='nearest',\n",
    "            ).numpy()\n",
    "        elif crop_method == 'cut':\n",
    "            frames = frames_data[:max_frames]\n",
    "        else:\n",
    "            raise Exception(f'{crop_method=} not found')\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750b0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.628516Z",
     "start_time": "2023-03-04T05:57:36.613536Z"
    }
   },
   "outputs": [],
   "source": [
    "def compress_frames(frames):\n",
    "    '''Make a video of shape (n_frames, pts, dims) --> (n_frames, pts*dims) '''\n",
    "    n_frames = frames.shape[0]\n",
    "    columns = frames.shape[1]*frames.shape[2]\n",
    "    return frames.reshape(n_frames, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce1b4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:36.641186Z",
     "start_time": "2023-03-04T05:57:36.629367Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_FRAMES = 20\n",
    "frames_reduced = load_frames(data1, max_frames=MAX_FRAMES)\n",
    "data_resize = compress_frames(frames_reduced)\n",
    "data_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25d389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:49.269983Z",
     "start_time": "2023-03-04T05:57:36.642026Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_FRAMES = 20\n",
    "N_PTS = 543\n",
    "N_DIMS = 3\n",
    "X_npy_fname = f'X-{MAX_FRAMES}_frames-pts_flattened.npy'\n",
    "y_npy_fname = f'y.npy'\n",
    "\n",
    "\n",
    "if CFG.is_training:\n",
    "    try:\n",
    "        X = np.load(X_npy_fname)\n",
    "        y = np.load(y_npy_fname)\n",
    "    except:\n",
    "        X = np.zeros((len(train), MAX_FRAMES, N_PTS*N_DIMS))\n",
    "        y = np.zeros((len(train),))\n",
    "        num_frames = np.zeros(len(train))\n",
    "        for i in tqdm(range(len(train))):\n",
    "            path = f\"{CFG.data_path}{train.iloc[i].path}\"\n",
    "            data = load_relevant_data_subset_with_imputation(path)\n",
    "            ## Mean Aggregation\n",
    "            frames_reduced = load_frames(data, max_frames=MAX_FRAMES)\n",
    "            data_resize = compress_frames(frames_reduced)\n",
    "            X[i] = data_resize\n",
    "            y[i] = train.iloc[i].label\n",
    "            num_frames[i] = data.shape[0]\n",
    "        ## Save number of frames of each training sample for data analysis\n",
    "        train[\"num_frames\"] = num_frames\n",
    "        print(train[\"num_frames\"].describe())\n",
    "        train.to_csv(\"train.csv\", index=False)\n",
    "        np.save(X_npy_fname, X)\n",
    "        np.save(y_npy_fname, y)\n",
    "\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d531286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:52.873328Z",
     "start_time": "2023-03-04T05:57:49.271603Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db5b7f",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "\n",
    "> https://keras.io/examples/vision/video_transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d00eb1",
   "metadata": {},
   "source": [
    "## Transformer Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79456ef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:52.878784Z",
     "start_time": "2023-03-04T05:57:52.874914Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = tf.keras.layers.Embedding(\n",
    "            input_dim=sequence_length,\n",
    "            output_dim=output_dim,\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19912ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:52.902765Z",
     "start_time": "2023-03-04T05:57:52.880207Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dense_dim, activation=tf.nn.gelu),\n",
    "            tf.keras.layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374bb5e",
   "metadata": {},
   "source": [
    "## Utility functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ab4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:52.913731Z",
     "start_time": "2023-03-04T05:57:52.904648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = N_PTS*N_DIMS #1024\n",
    "\n",
    "EPOCHS = 5\n",
    "def get_compiled_model(\n",
    "    sequence_length=MAX_FRAMES,\n",
    "    embed_dim=NUM_FEATURES,\n",
    "    dense_dim=4,\n",
    "    num_heads=1,\n",
    "):\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    embed_dim = NUM_FEATURES\n",
    "    dense_dim = 4\n",
    "    num_heads = 1\n",
    "    classes = 250 #len(label_processor.get_vocabulary())\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None))\n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(inputs)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a5fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:57:52.929660Z",
     "start_time": "2023-03-04T05:57:52.914698Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    validation_data = None,\n",
    "    validation_split: int = 0.2,\n",
    "    model_path: str = 'temp',\n",
    "    epochs: int = 10,\n",
    "    monitor_metric: str = 'val_accuracy',\n",
    "    patience: int = 4,\n",
    "):\n",
    "    checkpoint = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            model_path,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    model = get_compiled_model()\n",
    "    print(model.summary())\n",
    "        \n",
    "    fit_params = dict(\n",
    "        x=train_data,\n",
    "        y=train_labels,\n",
    "        validation_split=0.15,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    if validation_data:\n",
    "        fit_params['validation_data'] = validation_data\n",
    "    else:\n",
    "        fit_params['validation_split'] = validation_split\n",
    "    history = model.fit(\n",
    "        **fit_params,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    model.load_weights(model_path)\n",
    "    _, accuracy = model.evaluate(X_val, y_val)\n",
    "    print(f'Validation accuracy: {accuracy:.2%}')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a7e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T05:58:08.687403Z",
     "start_time": "2023-03-04T05:57:52.931004Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model, history = run_experiment(\n",
    "    train_data=X_train,\n",
    "    train_labels=y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    model_path='model_test-enc.h5',\n",
    "    epochs=200,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
