{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c8a3c0",
   "metadata": {},
   "source": [
    "Baseline_TF\n",
    "https://www.kaggle.com/code/ivaneleskin/baseline-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743607ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:49.596145Z",
     "start_time": "2023-02-27T23:48:47.956216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:48:48.191699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 15:48:48.335585: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-27 15:48:48.812383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-02-27 15:48:48.812445: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/:/home/victor/miniconda3/envs/tf/lib/\n",
      "2023-02-27 15:48:48.812449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import missingno as msno\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee4aeb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:49.685482Z",
     "start_time": "2023-02-27T23:48:49.597876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 94477 rows, 4 cols\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  \n",
       "0   blow  \n",
       "1   wait  \n",
       "2  cloud  \n",
       "3   bird  \n",
       "4   owie  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path('..')\n",
    "DF_TRAIN = DATA_ROOT / 'train.csv'\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "train.info()\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca81b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T18:53:45.403059Z",
     "start_time": "2023-02-27T18:53:45.006670Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11726f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:49.691094Z",
     "start_time": "2023-02-27T23:48:49.686854Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = \"../\"\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150fc1bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:49.781501Z",
     "start_time": "2023-02-27T23:48:49.692774Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda181c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:49.911764Z",
     "start_time": "2023-02-27T23:48:49.783022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(94477, 543, 3) (94477,)\n"
     ]
    }
   ],
   "source": [
    "if CFG.is_training:\n",
    "    print('True')\n",
    "#     if CFG.use_aggregation_dataset == True:\n",
    "    try:\n",
    "        X=  np.load('X_3d.npy')\n",
    "        y= np.load('y_3d.npy')\n",
    "    except:\n",
    "        print('True')\n",
    "        xs, ys = [], []\n",
    "        num_frames = np.zeros(len(train))\n",
    "        for i in tqdm(range(len(train))):\n",
    "            path = f\"{CFG.data_path}{train.iloc[i].path}\"\n",
    "            data = load_relevant_data_subset_with_imputation(path)\n",
    "            ## Mean Aggregation\n",
    "            xs.append(np.mean(data, axis=0))\n",
    "            ys.append(train.iloc[i].label)\n",
    "            num_frames[i] = data.shape[0]\n",
    "            if CFG.quick_experiment and i == 4999:\n",
    "                break\n",
    "        ## Save number of frames of each training sample for data analysis\n",
    "        train[\"num_frames\"] = num_frames\n",
    "        X, y = np.array(xs), np.array(ys)\n",
    "        print(train[\"num_frames\"].describe())\n",
    "        train.to_csv(\"train.csv\", index=False)\n",
    "        np.save('X_3d.npy', X)\n",
    "        np.save('y_3d.npy', y)\n",
    "\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54421556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T23:48:50.872623Z",
     "start_time": "2023-02-27T23:48:49.913298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:48:49.967442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:49.971369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:49.971529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:49.972101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 15:48:49.975343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:49.975489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:49.975764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:50.371069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:50.371270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:50.371407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 15:48:50.371523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21824 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(256, return_sequences=True, input_shape=[None,3]),\n",
    "    tf.keras.layers.GRU(256),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(250, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top-5-accuracy\"),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28309e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:36.975629Z",
     "start_time": "2023-02-27T23:48:50.873969Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75581, 543, 3) (75581,) (18896, 543, 3) (18896,)\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 15:48:53.564693: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-02-27 15:48:54.218831: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 46s 74ms/step - loss: 5.2788 - accuracy: 0.0171 - top-5-accuracy: 0.0675 - sparse_top_k_categorical_accuracy: 0.1181 - val_loss: 5.1083 - val_accuracy: 0.0234 - val_top-5-accuracy: 0.0958 - val_sparse_top_k_categorical_accuracy: 0.1678\n",
      "Epoch 2/120\n",
      "591/591 [==============================] - 44s 75ms/step - loss: 4.6593 - accuracy: 0.0581 - top-5-accuracy: 0.1923 - sparse_top_k_categorical_accuracy: 0.2996 - val_loss: 4.4207 - val_accuracy: 0.0765 - val_top-5-accuracy: 0.2507 - val_sparse_top_k_categorical_accuracy: 0.3716\n",
      "Epoch 3/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 4.1954 - accuracy: 0.1029 - top-5-accuracy: 0.3066 - sparse_top_k_categorical_accuracy: 0.4403 - val_loss: 4.1202 - val_accuracy: 0.1178 - val_top-5-accuracy: 0.3295 - val_sparse_top_k_categorical_accuracy: 0.4605\n",
      "Epoch 4/120\n",
      "591/591 [==============================] - 44s 75ms/step - loss: 3.8345 - accuracy: 0.1508 - top-5-accuracy: 0.4003 - sparse_top_k_categorical_accuracy: 0.5397 - val_loss: 3.8877 - val_accuracy: 0.1482 - val_top-5-accuracy: 0.3874 - val_sparse_top_k_categorical_accuracy: 0.5232\n",
      "Epoch 5/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 3.5473 - accuracy: 0.1946 - top-5-accuracy: 0.4690 - sparse_top_k_categorical_accuracy: 0.6080 - val_loss: 3.6112 - val_accuracy: 0.1907 - val_top-5-accuracy: 0.4464 - val_sparse_top_k_categorical_accuracy: 0.5829\n",
      "Epoch 6/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 3.3109 - accuracy: 0.2327 - top-5-accuracy: 0.5225 - sparse_top_k_categorical_accuracy: 0.6559 - val_loss: 3.2540 - val_accuracy: 0.2430 - val_top-5-accuracy: 0.5358 - val_sparse_top_k_categorical_accuracy: 0.6697\n",
      "Epoch 7/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 3.0941 - accuracy: 0.2699 - top-5-accuracy: 0.5735 - sparse_top_k_categorical_accuracy: 0.7013 - val_loss: 3.1906 - val_accuracy: 0.2569 - val_top-5-accuracy: 0.5506 - val_sparse_top_k_categorical_accuracy: 0.6753\n",
      "Epoch 8/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 2.9103 - accuracy: 0.3019 - top-5-accuracy: 0.6132 - sparse_top_k_categorical_accuracy: 0.7357 - val_loss: 3.0407 - val_accuracy: 0.2823 - val_top-5-accuracy: 0.5840 - val_sparse_top_k_categorical_accuracy: 0.7077\n",
      "Epoch 9/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.7526 - accuracy: 0.3332 - top-5-accuracy: 0.6476 - sparse_top_k_categorical_accuracy: 0.7624 - val_loss: 2.8856 - val_accuracy: 0.3099 - val_top-5-accuracy: 0.6192 - val_sparse_top_k_categorical_accuracy: 0.7360\n",
      "Epoch 10/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 2.6251 - accuracy: 0.3578 - top-5-accuracy: 0.6725 - sparse_top_k_categorical_accuracy: 0.7821 - val_loss: 2.7086 - val_accuracy: 0.3489 - val_top-5-accuracy: 0.6568 - val_sparse_top_k_categorical_accuracy: 0.7653\n",
      "Epoch 11/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.4837 - accuracy: 0.3900 - top-5-accuracy: 0.6993 - sparse_top_k_categorical_accuracy: 0.8018 - val_loss: 2.7639 - val_accuracy: 0.3350 - val_top-5-accuracy: 0.6452 - val_sparse_top_k_categorical_accuracy: 0.7637\n",
      "Epoch 12/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.4124 - accuracy: 0.4041 - top-5-accuracy: 0.7118 - sparse_top_k_categorical_accuracy: 0.8111 - val_loss: 2.6847 - val_accuracy: 0.3528 - val_top-5-accuracy: 0.6587 - val_sparse_top_k_categorical_accuracy: 0.7670\n",
      "Epoch 13/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.3029 - accuracy: 0.4264 - top-5-accuracy: 0.7345 - sparse_top_k_categorical_accuracy: 0.8267 - val_loss: 2.5582 - val_accuracy: 0.3806 - val_top-5-accuracy: 0.6876 - val_sparse_top_k_categorical_accuracy: 0.7880\n",
      "Epoch 14/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.2155 - accuracy: 0.4452 - top-5-accuracy: 0.7480 - sparse_top_k_categorical_accuracy: 0.8376 - val_loss: 2.4458 - val_accuracy: 0.4039 - val_top-5-accuracy: 0.7063 - val_sparse_top_k_categorical_accuracy: 0.8020\n",
      "Epoch 15/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 2.1311 - accuracy: 0.4636 - top-5-accuracy: 0.7624 - sparse_top_k_categorical_accuracy: 0.8482 - val_loss: 2.3957 - val_accuracy: 0.4186 - val_top-5-accuracy: 0.7163 - val_sparse_top_k_categorical_accuracy: 0.8082\n",
      "Epoch 16/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 2.0506 - accuracy: 0.4805 - top-5-accuracy: 0.7775 - sparse_top_k_categorical_accuracy: 0.8585 - val_loss: 2.3807 - val_accuracy: 0.4187 - val_top-5-accuracy: 0.7227 - val_sparse_top_k_categorical_accuracy: 0.8134\n",
      "Epoch 17/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 1.9803 - accuracy: 0.4998 - top-5-accuracy: 0.7889 - sparse_top_k_categorical_accuracy: 0.8643 - val_loss: 2.4244 - val_accuracy: 0.4115 - val_top-5-accuracy: 0.7128 - val_sparse_top_k_categorical_accuracy: 0.8067\n",
      "Epoch 18/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 1.9430 - accuracy: 0.5057 - top-5-accuracy: 0.7932 - sparse_top_k_categorical_accuracy: 0.8691 - val_loss: 2.2933 - val_accuracy: 0.4359 - val_top-5-accuracy: 0.7361 - val_sparse_top_k_categorical_accuracy: 0.8242\n",
      "Epoch 19/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 1.8861 - accuracy: 0.5176 - top-5-accuracy: 0.8029 - sparse_top_k_categorical_accuracy: 0.8755 - val_loss: 2.2656 - val_accuracy: 0.4428 - val_top-5-accuracy: 0.7417 - val_sparse_top_k_categorical_accuracy: 0.8278\n",
      "Epoch 20/120\n",
      "591/591 [==============================] - 44s 75ms/step - loss: 1.8403 - accuracy: 0.5307 - top-5-accuracy: 0.8106 - sparse_top_k_categorical_accuracy: 0.8795 - val_loss: 2.1583 - val_accuracy: 0.4707 - val_top-5-accuracy: 0.7620 - val_sparse_top_k_categorical_accuracy: 0.8395\n",
      "Epoch 21/120\n",
      "591/591 [==============================] - 43s 73ms/step - loss: 1.7790 - accuracy: 0.5395 - top-5-accuracy: 0.8200 - sparse_top_k_categorical_accuracy: 0.8881 - val_loss: 2.2467 - val_accuracy: 0.4497 - val_top-5-accuracy: 0.7447 - val_sparse_top_k_categorical_accuracy: 0.8269\n",
      "Epoch 22/120\n",
      "591/591 [==============================] - 44s 74ms/step - loss: 1.7331 - accuracy: 0.5522 - top-5-accuracy: 0.8265 - sparse_top_k_categorical_accuracy: 0.8905 - val_loss: 2.2530 - val_accuracy: 0.4531 - val_top-5-accuracy: 0.7435 - val_sparse_top_k_categorical_accuracy: 0.8258\n",
      "Epoch 23/120\n",
      "591/591 [==============================] - 44s 75ms/step - loss: 1.6854 - accuracy: 0.5641 - top-5-accuracy: 0.8337 - sparse_top_k_categorical_accuracy: 0.8972 - val_loss: 2.1848 - val_accuracy: 0.4678 - val_top-5-accuracy: 0.7570 - val_sparse_top_k_categorical_accuracy: 0.8363\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, None, 256)         200448    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               64250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 659,450\n",
      "Trainable params: 659,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "#     del X, y\n",
    "    gc.collect()\n",
    "#     model = get_model()\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\"model.h5\"),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,),\n",
    "    ]\n",
    "    history = model.fit(X_train, y_train, epochs=120, validation_data=(X_val, y_val), batch_size=128, callbacks=callbacks)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"../model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151040f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.813440Z",
     "start_time": "2023-02-28T00:05:36.977425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6t82s19e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6t82s19e/assets\n",
      "2023-02-27 16:05:44.440703: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-02-27 16:05:44.440748: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-02-27 16:05:44.441323: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp6t82s19e\n",
      "2023-02-27 16:05:44.453346: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-27 16:05:44.453374: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp6t82s19e\n",
      "2023-02-27 16:05:44.490857: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-02-27 16:05:44.502059: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-02-27 16:05:44.601453: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp6t82s19e\n",
      "2023-02-27 16:05:44.671927: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 230604 microseconds.\n",
      "2023-02-27 16:05:44.839099: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "loc(callsite(callsite(callsite(fused[\"TensorListReserve:\", callsite(\"TensorArrayV2_1@__inference_standard_gru_110188\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))] at fused[\"PartitionedCall:\", callsite(\"sequential/gru/PartitionedCall@__inference__wrapped_model_110784\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))]) at fused[\"StatefulPartitionedCall:\", callsite(\"StatefulPartitionedCall@__inference_signature_wrapper_114121\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n",
      "loc(callsite(callsite(callsite(fused[\"TensorListReserve:\", callsite(\"TensorArrayV2_1@__inference_standard_gru_110188\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))] at fused[\"PartitionedCall:\", callsite(\"sequential/gru/PartitionedCall@__inference__wrapped_model_110784\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))]) at fused[\"StatefulPartitionedCall:\", callsite(\"StatefulPartitionedCall@__inference_signature_wrapper_114121\"(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1268:0) at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\":1232:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1249:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py\":205:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1319:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":1339:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":908:0 at callsite(\"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\":930:0 at callsite(\"/tmp/ipykernel_124420/3989328835.py\":2:0 at \"/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\":3433:0)))))))))]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n",
      "error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[0;32m----> 2\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the model.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_gru_with_dense.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py:930\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py:908\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m    907\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m--> 908\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py:1339\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1328\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m \n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_as_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1340\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py:1321\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1319\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir))\n\u001b[1;32m   1320\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[0;32m-> 1321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFLiteKerasModelConverterV2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/lite.py:1132\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing new converter: If you encounter a problem \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease file a bug. You can opt-out \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1129\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting experimental_new_converter=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_graphdef\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconverter_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tflite_model(\n\u001b[1;32m   1139\u001b[0m     result, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quant_mode, quant_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     report_error_message(\u001b[38;5;28mstr\u001b[39m(converter_error))\n\u001b[0;32m--> 212\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m converter_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m  \u001b[38;5;66;03m# Re-throws the exception.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:794\u001b[0m, in \u001b[0;36mconvert_graphdef\u001b[0;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39moutput_arrays\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mget_tensor_name(output_tensor))\n\u001b[0;32m--> 794\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_flags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_flags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_info_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_mlir_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_mlir_converter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:311\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model_flags_str, conversion_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_data \u001b[38;5;129;01min\u001b[39;00m _metrics_wrapper\u001b[38;5;241m.\u001b[39mretrieve_collected_errors():\n\u001b[1;32m    310\u001b[0m       converter_error\u001b[38;5;241m.\u001b[39mappend_error(error_data)\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converter_error\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_deprecated_conversion_binary(model_flags_str,\n\u001b[1;32m    314\u001b[0m                                          conversion_flags_str, input_data_str,\n\u001b[1;32m    315\u001b[0m                                          debug_info_str)\n",
      "\u001b[0;31mConverterError\u001b[0m: /home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n/home/victor/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model_gru_with_dense.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c667e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.815552Z",
     "start_time": "2023-02-28T00:05:45.815544Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b874f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.816402Z",
     "start_time": "2023-02-28T00:05:45.816395Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c5849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.817182Z",
     "start_time": "2023-02-28T00:05:45.817175Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d9a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.818046Z",
     "start_time": "2023-02-28T00:05:45.818039Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd5c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.818961Z",
     "start_time": "2023-02-28T00:05:45.818954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98593b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.819959Z",
     "start_time": "2023-02-28T00:05:45.819952Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "\n",
    "# for i in range(1, len(model.layers)):\n",
    "x = model.layers[0](x)\n",
    "x = model.layers[1](x)\n",
    "x = model.layers[2](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14097f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.820690Z",
     "start_time": "2023-02-28T00:05:45.820683Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inference_model(model):\n",
    "    inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "    x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "    x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "    \n",
    "    for i in range(0, len(model.layers)):\n",
    "        x = model.layers[i](x)\n",
    "    output = tf.keras.layers.Activation(activation=\"linear\", name=\"outputs\")(x)\n",
    "    inference_model = tf.keras.Model(inputs=inputs, outputs=output) \n",
    "    inference_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125786d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.821251Z",
     "start_time": "2023-02-28T00:05:45.821245Z"
    }
   },
   "outputs": [],
   "source": [
    "inference_model = get_inference_model(model)\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440704d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.821902Z",
     "start_time": "2023-02-28T00:05:45.821896Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n",
    "tflite_model = converter.convert()\n",
    "model_path = \"model.tflite\"\n",
    "# Save the model.\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c62ba46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.822511Z",
     "start_time": "2023-02-28T00:05:45.822504Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tflite.Interpreter(model_path)\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "corr = 0\n",
    "wrong = []\n",
    "for i in tqdm(range(100)):\n",
    "    frames = load_relevant_data_subset(f'../{train.iloc[i].path}')\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    sign = np.argmax(output[\"outputs\"])\n",
    "    if index_label[sign] == train.iloc[i].sign:\n",
    "        corr += 1\n",
    "    else:\n",
    "        wrong.append((index_label[sign], train.iloc[i].sign, train.iloc[i].path))\n",
    "\n",
    "    #     print(f\"Predicted label: {index_label[sign]}, Actual Label: {train.iloc[i].sign}\")\n",
    "\n",
    "\n",
    "    total = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea52da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.822988Z",
     "start_time": "2023-02-28T00:05:45.822982Z"
    }
   },
   "outputs": [],
   "source": [
    "r = f'''\n",
    "{total=}\n",
    "{corr=}\\t Percent: {corr/total:%}\n",
    "'''\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08905e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T00:05:45.824184Z",
     "start_time": "2023-02-28T00:05:45.824176Z"
    }
   },
   "outputs": [],
   "source": [
    "wrongs = pd.DataFrame(data=wrong, columns=['pred','true','path'])\n",
    "wrongs.groupby('pred').count().reset_index().sort_values('true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
