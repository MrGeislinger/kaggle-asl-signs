{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c8a3c0",
   "metadata": {},
   "source": [
    "Baseline_TF\n",
    "https://www.kaggle.com/code/ivaneleskin/baseline-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4d7e4e-fd2b-4aad-b4b4-175d5168c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743607ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T19:53:50.745887Z",
     "start_time": "2023-03-05T19:53:48.345036Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import missingno as msno\n",
    "import multiprocessing as mp\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee4aeb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T19:53:50.835545Z",
     "start_time": "2023-03-05T19:53:50.747575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 94477 rows, 4 cols\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  \n",
       "0   blow  \n",
       "1   wait  \n",
       "2  cloud  \n",
       "3   bird  \n",
       "4   owie  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path('data')\n",
    "DF_TRAIN = DATA_ROOT / 'train.csv'\n",
    "train = pd.read_csv(DF_TRAIN)\n",
    "\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "train.info()\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11726f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T19:53:51.654266Z",
     "start_time": "2023-03-05T19:53:51.648285Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_path = \"data/\"\n",
    "    quick_experiment = False\n",
    "    is_training = True\n",
    "    use_aggregation_dataset = True\n",
    "    num_classes = 250\n",
    "    rows_per_frame = 543 \n",
    "\n",
    "def load_relevant_data_subset_with_imputation(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    data.replace(np.nan, 0, inplace=True)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / CFG.rows_per_frame)\n",
    "    data = data.values.reshape(n_frames, CFG.rows_per_frame, len(data_columns))\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def read_dict(file_path):\n",
    "    path = os.path.expanduser(file_path)\n",
    "    with open(path, \"r\") as f:\n",
    "        dic = json.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150fc1bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:14:13.609475Z",
     "start_time": "2023-02-28T05:14:13.515016Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "index_label = {label_index[key]: key for key in label_index}\n",
    "train[\"label\"] = train[\"sign\"].map(lambda sign: label_index[sign])\n",
    "\n",
    "features_filename = 'feature_data_keyframes.npy'\n",
    "labels_filename = 'feature_labels_keyframes.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fda181c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T20:01:41.987102Z",
     "start_time": "2023-03-05T20:01:15.330743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                               | 0/94477 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 33, 2)\n",
      "(3258,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "import multiprocessing as mp\n",
    "\n",
    "def first_and_2_disparate_key_frame(data):\n",
    "    # Initialize variables to store the maximum distance and the corresponding points\n",
    "    max_distance = 0\n",
    "    frame0 = 0\n",
    "    frame1 = 0\n",
    "    frame2 = 0\n",
    "    point1 = None\n",
    "    point2 = None\n",
    "\n",
    "    where_are_NaNs = np.isnan(data)\n",
    "    data[where_are_NaNs] = 0\n",
    "\n",
    "    # Loop over all pairs of points in the array\n",
    "    # and Compute the Euclidean distance between the current pair of points\n",
    "    for i in range(1,data.shape[0]):\n",
    "        for j in range(i+1, data.shape[0]):\n",
    "            # Check if both points have all zeros for their coordinates\n",
    "            if np.all(data[i] == 0) or np.all(data[j] == 0):\n",
    "                print(\"Skipping zero-frame\")\n",
    "                continue\n",
    "\n",
    "            distance = np.linalg.norm(data[j] - data[i])\n",
    "            # If the distance is larger than the current maximum, update the maximum and the corresponding points\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "                point1 = data[i]\n",
    "                point2 = data[j]\n",
    "                frame1 = i\n",
    "                frame2 = j\n",
    "\n",
    "    data_new = np.zeros((3,543,3))\n",
    "    data_new[0] = data[frame0,:,:]\n",
    "    data_new[1] = data[frame1,:,:]\n",
    "    data_new[2] = data[frame2,:,:]\n",
    "    return data_new\n",
    "\n",
    "def convert_row(row):\n",
    "    _, row = row\n",
    "    x = load_relevant_data_subset(f\"{CFG.data_path}{row.path}\")\n",
    "    x = first_and_2_disparate_key_frame(x)\n",
    "\n",
    "    # Feature Converter code - START    \n",
    "    FRAMES = 3\n",
    "    # Drop Z coordinate so we multiply by 2\n",
    "    face_x = x[:,:468,:2].reshape(-1, FRAMES*468*2) # Flatten array \n",
    "    lefth_x = x[:,468:489,:2].reshape(-1, FRAMES*21*2)\n",
    "    pose_x = x[:,489:522,:2].reshape(-1, FRAMES*33*2)\n",
    "    righth_x = x[:,522:,:2].reshape(-1, FRAMES*21*2)\n",
    "\n",
    "    # Concatenate features\n",
    "    xs = [] \n",
    "    xs.append(face_x)\n",
    "    xs.append(lefth_x)\n",
    "    xs.append(pose_x)\n",
    "    xs.append(righth_x)\n",
    "    xfeat = np.zeros(sum(x.shape[1] for x in xs))\n",
    "    start_index = 0\n",
    "    for x in xs:\n",
    "        xfeat[start_index:start_index+x.shape[1]] = x\n",
    "        start_index += x.shape[1]\n",
    "    # Feature Converter code - END\n",
    "    return xfeat, row.label\n",
    "\n",
    "def convert_and_save_data():\n",
    "    df = train\n",
    "    df = pd.read_csv(f\"{CFG.data_path}train.csv\")\n",
    "    \n",
    "    label_index = read_dict(f\"{CFG.data_path}sign_to_prediction_index_map.json\")\n",
    "    index_label = {label_index[key]: key for key in label_index}\n",
    "    df[\"label\"] = df[\"sign\"].map(lambda sign: label_index[sign])    \n",
    "    \n",
    "    npdata = np.zeros((df.shape[0], 3258))\n",
    "    nplabels = np.zeros(df.shape[0])\n",
    "\n",
    "    # for row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "    #     i = row[0]\n",
    "    #     x, y = convert_row(row)\n",
    "    #     npdata[i,:] = x\n",
    "    #     nplabels[i] = y\n",
    "    \n",
    "    with mp.Pool(processes=16) as pool:\n",
    "        results = pool.imap_unordered(convert_row, df.iterrows(), chunksize=250)\n",
    "        for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            npdata[i,:] = x\n",
    "            nplabels[i] = y\n",
    "            \n",
    "    np.save(features_filename, npdata)\n",
    "    np.save(labels_filename, nplabels)\n",
    "convert_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a7d7d-63ec-4a20-8dc6-c5eb64637d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(features_filename)\n",
    "y = np.load(labels_filename)\n",
    "\n",
    "## Save number of frames of each training sample for data analysis\n",
    "# train[\"num_frames\"] = num_frames\n",
    "# print(train[\"num_frames\"].describe())\n",
    "# train.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54421556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:14:14.890697Z",
     "start_time": "2023-02-28T05:14:13.741748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.GRU(256, return_sequences=True, input_shape=[None, 3]),\n",
    "#     tf.keras.layers.GRU(256),\n",
    "#     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(250, activation=\"softmax\"),\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential([    \n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"gelu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"gelu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(250, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer='adam',\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        # tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top-05-acc\"),\n",
    "        # tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name=\"top-10-acc\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4982c5-afc2-4a6b-9ea2-4ed08fda4af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "\n",
    "# Double the training data by mirroring the coordinates over the x-axis\n",
    "# X_train_mirrored = X_train.copy()\n",
    "# X_train_mirrored[:,:,0] *= -1 # flip over x-axis to mirror the data\n",
    "# y_train = np.concatenate((y_train, y_train))\n",
    "# X_train = np.concatenate((X_train, X_train_mirrored))\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28309e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:46.380460Z",
     "start_time": "2023-02-28T05:14:14.892263Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"model.h5\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs/fit/' + datetime.datetime.now().strftime(\"%Y$Ym%d-%H%M%S-keyframes\"), histogram_freq=1),\n",
    "]\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_val, y_val), batch_size=64, callbacks=callbacks)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c667e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:46.964014Z",
     "start_time": "2023-02-28T05:57:46.381837Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b874f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.066992Z",
     "start_time": "2023-02-28T05:57:46.965515Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c5849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.144224Z",
     "start_time": "2023-02-28T05:57:47.068112Z"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9411eb9-ae9c-4882-aa33-60d10d85c480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.147276Z",
     "start_time": "2023-02-28T05:57:47.145227Z"
    },
    "code_folding": []
   },
   "source": [
    "## def get_model():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd5c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.171475Z",
     "start_time": "2023-02-28T05:57:47.148189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98593b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.376497Z",
     "start_time": "2023-02-28T05:57:47.172285Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "# x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "# x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "\n",
    "# # for i in range(1, len(model.layers)):\n",
    "# x = model.layers[0](x)\n",
    "# x = model.layers[1](x)\n",
    "# x = model.layers[2](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14097f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.382047Z",
     "start_time": "2023-02-28T05:57:47.378515Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_inference_model(model):\n",
    "    inputs = tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")\n",
    "    x = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs)\n",
    "    x = tf.reduce_mean(x, axis=0, keepdims=True)\n",
    "    \n",
    "    for i in range(0, len(model.layers)):\n",
    "        x = model.layers[i](x)\n",
    "    output = tf.keras.layers.Activation(activation=\"linear\", name=\"outputs\")(x)\n",
    "    inference_model = tf.keras.Model(inputs=inputs, outputs=output) \n",
    "    inference_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    \n",
    "    return inference_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b125786d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:47.644935Z",
     "start_time": "2023-02-28T05:57:47.382791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 543, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.math.is_nan_1 (TFOpLambda)  (None, 543, 3)       0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.zeros_like_1 (TFOpLambda)   (None, 543, 3)       0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.where_1 (TFOpLambda)        (None, 543, 3)       0           ['tf.math.is_nan_1[0][0]',       \n",
      "                                                                  'tf.zeros_like_1[0][0]',        \n",
      "                                                                  'inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (1, 543, 3)         0           ['tf.where_1[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " gru (GRU)                      multiple             200448      ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    multiple             394752      ['gru[2][0]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  multiple             65792       ['gru_1[2][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              multiple             0           ['dense[2][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                multiple             32896       ['dropout[1][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                multiple             16512       ['dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            multiple             0           ['dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                multiple             8256        ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            multiple             0           ['dense_3[1][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                multiple             4160        ['dropout_2[1][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              multiple             0           ['dense_4[1][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                multiple             16250       ['flatten[1][0]']                \n",
      "                                                                                                  \n",
      " outputs (Activation)           (1, 250)             0           ['dense_5[1][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 739,066\n",
      "Trainable params: 739,066\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model = get_inference_model(model)\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2440704d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:57:55.230706Z",
     "start_time": "2023-02-28T05:57:47.646015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1ibqbx5a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1ibqbx5a/assets\n",
      "2023-03-04 20:00:43.060194: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-04 20:00:43.060240: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-04 20:00:43.060400: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp1ibqbx5a\n",
      "2023-03-04 20:00:43.071015: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-04 20:00:43.071046: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp1ibqbx5a\n",
      "2023-03-04 20:00:43.111780: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-03-04 20:00:43.191194: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp1ibqbx5a\n",
      "2023-03-04 20:00:43.253644: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 193243 microseconds.\n",
      "2023-03-04 20:00:43.584706: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 1.593 M  ops, equivalently 0.796 M  MACs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n",
    "tflite_model = converter.convert()\n",
    "model_path = \"model.tflite\"\n",
    "# Save the model.\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fd967af-1053-4434-9359-90f00cd424e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/victor/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "total 643M\n",
      "-rw-rw-r-- 1 victor victor 351K Mar  4 16:56 animations.ipynb\n",
      "-rw-rw-r-- 1 victor victor  62K Mar  4 16:56 baseline-deep_wide.ipynb\n",
      "-rw-rw-r-- 1 victor victor 262K Mar  4 16:56 baseline-GRU-avg_interpolated_frames.ipynb\n",
      "-rw-rw-r-- 1 victor victor 236K Mar  4 18:57 baseline-GRU-avg_interpolated_frames-split_inputs.ipynb\n",
      "-rw-rw-r-- 1 victor victor 147K Mar  4 20:00 baseline-GRU-Beefier.ipynb\n",
      "-rw-rw-r-- 1 victor victor 140K Mar  4 16:56 baseline-GRU.ipynb\n",
      "-rw-rw-r-- 1 victor victor 8.9K Mar  4 16:56 environment.yml\n",
      "-rw-rw-r-- 1 victor victor  30M Mar  4 18:20 model-Copy1.h5\n",
      "-rw-rw-r-- 1 victor victor 8.6M Mar  4 19:53 model.h5\n",
      "-rw-rw-r-- 1 victor victor 3.4M Mar  4 20:00 model.tflite\n",
      "-rw-rw-r-- 1 victor victor 8.6M Mar  4 19:45 model-v1.h5\n",
      "-rw-rw-r-- 1 victor victor 3.4M Mar  4 20:01 submission.zip\n",
      "-rw-rw-r-- 1 victor victor  17K Mar  4 16:56 transformer-based-model.ipynb\n",
      "-rw-rw-r-- 1 victor victor 588M Mar  4 17:02 X_3d-mean.npy\n",
      "-rw-rw-r-- 1 victor victor 739K Mar  4 17:03 y_3d-mean.npy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c62ba46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:58:11.418380Z",
     "start_time": "2023-02-28T05:57:55.232237Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▍                                                                                                             | 3/100 [00:00<00:07, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: brown, Actual Label: blow\n",
      "Predicted label: shirt, Actual Label: wait\n",
      "Predicted label: rain, Actual Label: cloud\n",
      "Predicted label: bird, Actual Label: bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▉                                                                                                         | 7/100 [00:00<00:06, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: owie, Actual Label: owie\n",
      "Predicted label: duck, Actual Label: duck\n",
      "Predicted label: please, Actual Label: minemy\n",
      "Predicted label: red, Actual Label: lips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▎                                                                                                   | 11/100 [00:00<00:05, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: flower, Actual Label: flower\n",
      "Predicted label: donkey, Actual Label: time\n",
      "Predicted label: vacuum, Actual Label: vacuum\n",
      "Predicted label: apple, Actual Label: apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▊                                                                                               | 15/100 [00:01<00:05, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: any, Actual Label: puzzle\n",
      "Predicted label: mitten, Actual Label: mitten\n",
      "Predicted label: room, Actual Label: there\n",
      "Predicted label: dryer, Actual Label: dry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▎                                                                                          | 19/100 [00:01<00:05, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: shirt, Actual Label: shirt\n",
      "Predicted label: owl, Actual Label: owl\n",
      "Predicted label: yellow, Actual Label: yellow\n",
      "Predicted label: sleepy, Actual Label: time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▊                                                                                      | 23/100 [00:01<00:04, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: not, Actual Label: not\n",
      "Predicted label: zipper, Actual Label: zipper\n",
      "Predicted label: dirty, Actual Label: clean\n",
      "Predicted label: closet, Actual Label: closet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████▏                                                                                 | 27/100 [00:01<00:04, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: table, Actual Label: quiet\n",
      "Predicted label: have, Actual Label: have\n",
      "Predicted label: brother, Actual Label: brother\n",
      "Predicted label: food, Actual Label: clown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████▋                                                                             | 31/100 [00:02<00:04, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: ear, Actual Label: cheek\n",
      "Predicted label: cute, Actual Label: cute\n",
      "Predicted label: store, Actual Label: store\n",
      "Predicted label: shoe, Actual Label: shoe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████▏                                                                        | 35/100 [00:02<00:04, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: wet, Actual Label: wet\n",
      "Predicted label: shirt, Actual Label: shirt\n",
      "Predicted label: see, Actual Label: see\n",
      "Predicted label: empty, Actual Label: empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████████████▋                                                                    | 39/100 [00:02<00:03, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: zebra, Actual Label: fall\n",
      "Predicted label: balloon, Actual Label: balloon\n",
      "Predicted label: frenchfries, Actual Label: frenchfries\n",
      "Predicted label: finger, Actual Label: finger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████████████▏                                                               | 43/100 [00:02<00:03, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: same, Actual Label: same\n",
      "Predicted label: car, Actual Label: cry\n",
      "Predicted label: mouth, Actual Label: hungry\n",
      "Predicted label: beside, Actual Label: owl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████████████▋                                                           | 47/100 [00:03<00:03, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: not, Actual Label: orange\n",
      "Predicted label: cloud, Actual Label: cloud\n",
      "Predicted label: car, Actual Label: milk\n",
      "Predicted label: outside, Actual Label: go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████████████████████                                                       | 51/100 [00:03<00:03, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: store, Actual Label: store\n",
      "Predicted label: vacuum, Actual Label: drawer\n",
      "Predicted label: TV, Actual Label: TV\n",
      "Predicted label: dryer, Actual Label: dry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████████████████████▌                                                  | 55/100 [00:03<00:02, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: duck, Actual Label: duck\n",
      "Predicted label: blow, Actual Label: blow\n",
      "Predicted label: puzzle, Actual Label: another\n",
      "Predicted label: giraffe, Actual Label: giraffe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████████████████████                                              | 59/100 [00:03<00:02, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: wake, Actual Label: wake\n",
      "Predicted label: after, Actual Label: bee\n",
      "Predicted label: shirt, Actual Label: bad\n",
      "Predicted label: where, Actual Label: can\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████████████████▌                                         | 63/100 [00:04<00:02, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: food, Actual Label: flower\n",
      "Predicted label: say, Actual Label: say\n",
      "Predicted label: callonphone, Actual Label: callonphone\n",
      "Predicted label: finish, Actual Label: finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████████████████████████                                     | 67/100 [00:04<00:02, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: bee, Actual Label: bee\n",
      "Predicted label: orange, Actual Label: old\n",
      "Predicted label: ear, Actual Label: backyard\n",
      "Predicted label: sick, Actual Label: sick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████████████████████████████████████████████████████████████████████████████▌                                | 71/100 [00:04<00:01, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: TV, Actual Label: look\n",
      "Predicted label: that, Actual Label: that\n",
      "Predicted label: smile, Actual Label: black\n",
      "Predicted label: haveto, Actual Label: yourself\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████                            | 75/100 [00:04<00:01, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: open, Actual Label: open\n",
      "Predicted label: alligator, Actual Label: alligator\n",
      "Predicted label: wet, Actual Label: wet\n",
      "Predicted label: closet, Actual Label: closet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████████████████████████████▍                       | 79/100 [00:05<00:01, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: awake, Actual Label: moon\n",
      "Predicted label: snow, Actual Label: find\n",
      "Predicted label: read, Actual Label: pizza\n",
      "Predicted label: shhh, Actual Label: shhh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████▉                   | 83/100 [00:05<00:01, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: car, Actual Label: fast\n",
      "Predicted label: pajamas, Actual Label: jacket\n",
      "Predicted label: scissors, Actual Label: scissors\n",
      "Predicted label: now, Actual Label: now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████▍              | 87/100 [00:05<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: TV, Actual Label: TV\n",
      "Predicted label: wake, Actual Label: wake\n",
      "Predicted label: owl, Actual Label: man\n",
      "Predicted label: sticky, Actual Label: sticky\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 91/100 [00:05<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: ride, Actual Label: jump\n",
      "Predicted label: sleepy, Actual Label: sleep\n",
      "Predicted label: pretty, Actual Label: sun\n",
      "Predicted label: first, Actual Label: first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 95/100 [00:06<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: callonphone, Actual Label: yellow\n",
      "Predicted label: brown, Actual Label: brother\n",
      "Predicted label: grass, Actual Label: grass\n",
      "Predicted label: uncle, Actual Label: uncle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: fish, Actual Label: fish\n",
      "Predicted label: lamp, Actual Label: scissors\n",
      "Predicted label: cowboy, Actual Label: cowboy\n",
      "Predicted label: finish, Actual Label: snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tflite.Interpreter(model_path)\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "corr = 0\n",
    "wrong = []\n",
    "for i in tqdm(range(100)):\n",
    "    frames = load_relevant_data_subset(f\"{CFG.data_path}{train.iloc[i].path}\")\n",
    "    output = prediction_fn(inputs=frames)\n",
    "    sign = np.argmax(output[\"outputs\"])\n",
    "    if index_label[sign] == train.iloc[i].sign:\n",
    "        corr += 1\n",
    "    else:\n",
    "        wrong.append((index_label[sign], train.iloc[i].sign, train.iloc[i].path))\n",
    "    print(f\"Predicted label: {index_label[sign]}, Actual Label: {train.iloc[i].sign}\")\n",
    "    total = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ea52da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:58:11.422857Z",
     "start_time": "2023-02-28T05:58:11.420044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total=99\n",
      "corr=54\t Percent: 54.545455%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = f'''\n",
    "{total=}\n",
    "{corr=}\\t Percent: {corr/total:%}\n",
    "'''\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08905e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T05:58:11.447508Z",
     "start_time": "2023-02-28T05:58:11.424261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>owl</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pajamas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>please</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rain</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>outside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ride</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>room</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>smile</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>snow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>table</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vacuum</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>where</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>orange</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mouth</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>callonphone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dirty</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>finish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>haveto</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lamp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>donkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dryer</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ear</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>brown</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>shirt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>food</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred  true  path\n",
       "0            TV     1     1\n",
       "20          owl     1     1\n",
       "21      pajamas     1     1\n",
       "22       please     1     1\n",
       "23       pretty     1     1\n",
       "24       puzzle     1     1\n",
       "25         rain     1     1\n",
       "19      outside     1     1\n",
       "26         read     1     1\n",
       "28         ride     1     1\n",
       "29         room     1     1\n",
       "32        smile     1     1\n",
       "33         snow     1     1\n",
       "34        table     1     1\n",
       "35       vacuum     1     1\n",
       "27          red     1     1\n",
       "36        where     1     1\n",
       "18       orange     1     1\n",
       "16        mouth     1     1\n",
       "1         after     1     1\n",
       "2           any     1     1\n",
       "3         awake     1     1\n",
       "4        beside     1     1\n",
       "6   callonphone     1     1\n",
       "17          not     1     1\n",
       "8         dirty     1     1\n",
       "37        zebra     1     1\n",
       "12       finish     1     1\n",
       "14       haveto     1     1\n",
       "15         lamp     1     1\n",
       "9        donkey     1     1\n",
       "10        dryer     2     2\n",
       "11          ear     2     2\n",
       "5         brown     2     2\n",
       "30        shirt     2     2\n",
       "31       sleepy     2     2\n",
       "13         food     2     2\n",
       "7           car     3     3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongs = pd.DataFrame(data=wrong, columns=['pred','true','path'])\n",
    "wrongs.groupby('pred').count().reset_index().sort_values('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "711984aa-12ab-4a0d-8cb1-6e7df10fa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('submission.zip', mode='w').write('model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2a626-047a-4e2d-b63f-05edf7e32eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
